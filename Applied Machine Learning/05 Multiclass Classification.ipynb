{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKsRDH5ZUdfasdv"
   },
   "source": [
    "# Lab 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43534tdfgs-v"
   },
   "source": [
    "This lab extends binary logistic regression to [multi-class logistic regression](https://en.wikipedia.org/wiki/Multinomial_logistic_regression), which goes by a variety of names, including *softmax regression*, due to the use of the softmax function, which generalizes the logistic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3490,
     "status": "ok",
     "timestamp": 1620709486769,
     "user": {
      "displayName": "Daniel Gillick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9DrSMlwYnG9EolecuJqe8n9m7fpcje4_UbYrhQ10=s64",
      "userId": "01872965353911650729"
     },
     "user_tz": 420
    },
    "id": "7X58hOMTUH-w"
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "dlopen(/Users/mamesael/Tensorflow2/env/lib/python3.9/site-packages/tensorflow-plugins/libmetal_plugin.dylib, 0x0006): symbol not found in flat namespace '__ZN3tsl8internal10LogMessage16VmoduleActivatedEPKci'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m  \u001b[38;5;66;03m# for nicer plots\u001b[39;00m\n\u001b[1;32m      6\u001b[0m sns\u001b[38;5;241m.\u001b[39mset(style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdarkgrid\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# default style\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n",
      "File \u001b[0;32m~/Tensorflow2/env/lib/python3.9/site-packages/tensorflow/__init__.py:449\u001b[0m\n\u001b[1;32m    447\u001b[0m _plugin_dir \u001b[38;5;241m=\u001b[39m _os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_s, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow-plugins\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(_plugin_dir):\n\u001b[0;32m--> 449\u001b[0m   \u001b[43m_ll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_plugin_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m   \u001b[38;5;66;03m# Load Pluggable Device Library\u001b[39;00m\n\u001b[1;32m    451\u001b[0m   _ll\u001b[38;5;241m.\u001b[39mload_pluggable_device_library(_plugin_dir)\n",
      "File \u001b[0;32m~/Tensorflow2/env/lib/python3.9/site-packages/tensorflow/python/framework/load_library.py:155\u001b[0m, in \u001b[0;36mload_library\u001b[0;34m(library_location)\u001b[0m\n\u001b[1;32m    152\u001b[0m     kernel_libraries \u001b[38;5;241m=\u001b[39m [library_location]\n\u001b[1;32m    154\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m lib \u001b[38;5;129;01min\u001b[39;00m kernel_libraries:\n\u001b[0;32m--> 155\u001b[0m     \u001b[43mpy_tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_LoadLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlib\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    159\u001b[0m       errno\u001b[38;5;241m.\u001b[39mENOENT,\n\u001b[1;32m    160\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe file or folder to load kernel libraries from does not exist.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    161\u001b[0m       library_location)\n",
      "\u001b[0;31mNotFoundError\u001b[0m: dlopen(/Users/mamesael/Tensorflow2/env/lib/python3.9/site-packages/tensorflow-plugins/libmetal_plugin.dylib, 0x0006): symbol not found in flat namespace '__ZN3tsl8internal10LogMessage16VmoduleActivatedEPKci'"
     ]
    }
   ],
   "source": [
    "# Import the libraries we'll use below.\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns  # for nicer plots\n",
    "sns.set(style=\"darkgrid\")  # default style\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import metrics\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uq43KrCh8pe"
   },
   "source": [
    "We again load the Fashion MNIST dataset, though this time around, we'll use all 10 output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1905,
     "status": "ok",
     "timestamp": 1618441063929,
     "user": {
      "displayName": "Daniel Gillick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9DrSMlwYnG9EolecuJqe8n9m7fpcje4_UbYrhQ10=s64",
      "userId": "01872965353911650729"
     },
     "user_tz": 420
    },
    "id": "load_auto_data_set_code",
    "outputId": "36d947cb-8799-4e55-d208-fbc7350c0cc2"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "# Load the Fashion MNIST dataset.\n",
    "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# Flatten Y_train and Y_test, so they become vectors of label values.\n",
    "# The label for X_train[0] is in Y_train[0].\n",
    "Y_train = Y_train.flatten()\n",
    "Y_test = Y_test.flatten()\n",
    "\n",
    "label_names = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "               'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "\n",
    "# Apply random shufflying to training examples.\n",
    "np.random.seed(0)\n",
    "indices = np.arange(X_train.shape[0])\n",
    "shuffled_indices = np.random.permutation(indices)\n",
    "X_train = X_train[shuffled_indices]\n",
    "Y_train = Y_train[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsfzNnVFwh0K"
   },
   "source": [
    "### Cross-Entropy Loss\n",
    "\n",
    "Recall the log loss function (also called binary cross-entropy):\n",
    "\n",
    "\\begin{equation}\n",
    "-y log(\\hat{y}) + (1−y)log(1−\\hat{y})\n",
    "\\end{equation}\n",
    "\n",
    "In the above formulation, it is assumed that $y$ is either 0 or 1, so either the left term or the right term is active for each example.\n",
    "\n",
    "The general form for cross-entropy is used when $y$ is assumed to be a label vector with a 1 in the index of the true label and a 0 everywhere else: $y=[0,0,0,0,0,0,0,1,0,0]$ implies a label of \"sneaker\" in this dataset (the 7th label). Accordingly, $\\hat{y}$ is a vector of predicted probabilities. Then the cross-entropy loss is simply:\n",
    "\n",
    "\\begin{equation}\n",
    "-\\sum_{j} y_j log(\\hat{y}_j)\n",
    "\\end{equation}\n",
    "\n",
    "As in the binary case, this summation will have exactly 1 non-zero term where the true label $y_j=1$.\n",
    "\n",
    "Note that this formulation is using a *dense* representation of the label. The corresponding *sparse* representation would use the non-zero index directly ($y=7$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09EpBz1w0_Nj"
   },
   "source": [
    "## Build a model\n",
    "\n",
    "Let's construct a model much like we did in the binary classification case, but now with a multi-class output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75ur9Q_TOoxv"
   },
   "source": [
    "---\n",
    "### Exercise 1 (8 points)\n",
    "\n",
    "Fill in the NotImplemented parts of the build_model function below. You will need to make the following changes to generalize the binary case to the multi-class case:\n",
    "* The output will include 10 probabilities instead of 1.\n",
    "* Use a softmax function instead of a sigmoid.\n",
    "* Use a [sparse_categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy) loss instead of binary_crossentropy. Note that \"sparse\" refers to the use of a sparse index (e.g. 7) to indicate the label rather than a dense vector (e.g. [0,0,0,0,0,0,0,1,0,0]).\n",
    "\n",
    "Check that training works below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-GeBGPGhQ5bu"
   },
   "outputs": [],
   "source": [
    "def build_model(n_classes, learning_rate=0.01):\n",
    "  \"\"\"Build a multi-class logistic regression model using Keras.\n",
    "\n",
    "  Args:\n",
    "    n_classes: Number of classes in the dataset\n",
    "    learning_rate: The desired learning rate for SGD.\n",
    "\n",
    "  Returns:\n",
    "    model: A tf.keras model (graph).\n",
    "  \"\"\"\n",
    "  tf.keras.backend.clear_session()\n",
    "  np.random.seed(0)\n",
    "  tf.random.set_seed(0)\n",
    "\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten())\n",
    "  model.add(keras.layers.Dense(\n",
    "      # YOUR CODE HERE\n",
    "      units=3,\n",
    "      activation='linear'\n",
    "  ))\n",
    "\n",
    "  optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    \n",
    "  # YOUR CODE HERE\n",
    "  model.compile(loss='mse', \n",
    "                optimizer=optimizer, \n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DO-d_F58Q-6O"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNpKsUK6jt7-"
   },
   "source": [
    "Make sure your model trains. If you configured it properly, the training loss should get to ~0.55 after 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 7672,
     "status": "ok",
     "timestamp": 1618441373961,
     "user": {
      "displayName": "Daniel Gillick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9DrSMlwYnG9EolecuJqe8n9m7fpcje4_UbYrhQ10=s64",
      "userId": "01872965353911650729"
     },
     "user_tz": 420
    },
    "id": "dYRGXpzY1B5x",
    "outputId": "2b30c3ca-cfca-4160-86a9-5026697d685e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 22:14:40.700318: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-04 22:14:41.795601: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7f84724adf50\n",
      "2023-03-04 22:14:41.795670: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7f84724adf50\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall' defined at (most recent call last):\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/vm/r20zwxbd44vb57jqr7t56c7r0000gn/T/ipykernel_52586/1451841720.py\", line 3, in <module>\n      history = model.fit(\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 527, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 634, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1166, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1211, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall'\ncould not find registered platform with id: 0x7f84724adf50\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_train_function_653]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(\u001b[38;5;28mlen\u001b[39m(label_names), \u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m  \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m  \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m history \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(history\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[1;32m     12\u001b[0m display(history)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall' defined at (most recent call last):\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/vm/r20zwxbd44vb57jqr7t56c7r0000gn/T/ipykernel_52586/1451841720.py\", line 3, in <module>\n      history = model.fit(\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 527, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 634, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1166, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/Users/mamesael/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1211, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall'\ncould not find registered platform with id: 0x7f84724adf50\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_train_function_653]"
     ]
    }
   ],
   "source": [
    "model = build_model(len(label_names), 0.01)\n",
    "\n",
    "history = model.fit(\n",
    "  x = X_train,\n",
    "  y = Y_train,\n",
    "  epochs=5,\n",
    "  batch_size=64,\n",
    "  validation_split=0.1,\n",
    "  verbose=1)\n",
    "\n",
    "history = pd.DataFrame(history.history)\n",
    "display(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ALSrErIrrjW"
   },
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "Classification metrics like accuracy, precision, and recall can all be derived from a confusion matrix which displays the counts for all pairs of true label and predicted label. Correct predictions are on the diagonal and incorrect predictions (confusions) are off the diagonal.\n",
    "\n",
    "First, we need the predicted labels from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8936,
     "status": "ok",
     "timestamp": 1616042832272,
     "user": {
      "displayName": "Daniel Gillick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9DrSMlwYnG9EolecuJqe8n9m7fpcje4_UbYrhQ10=s64",
      "userId": "01872965353911650729"
     },
     "user_tz": 420
    },
    "id": "eBdgn9PUsHuq",
    "outputId": "4744e0bb-e67f-413c-ba24-ae7d65d9c69e"
   },
   "outputs": [],
   "source": [
    "# Recall that model.predict gives a vector of probabilities for each x.\n",
    "# Get labels by taking the argmax -- the index with the largest probability.\n",
    "test_predictions = np.argmax(model.predict(X_test), axis=-1)\n",
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pr8NOrQmfwsT"
   },
   "source": [
    "Next, we create a confusion matrix and produce an easy-to-read visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "executionInfo": {
     "elapsed": 9529,
     "status": "ok",
     "timestamp": 1616042832868,
     "user": {
      "displayName": "Daniel Gillick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9DrSMlwYnG9EolecuJqe8n9m7fpcje4_UbYrhQ10=s64",
      "userId": "01872965353911650729"
     },
     "user_tz": 420
    },
    "id": "juOwp33Wx_bR",
    "outputId": "5565824a-cf5f-450f-d54d-faf99c613c70"
   },
   "outputs": [],
   "source": [
    "# Create a confusion matrix as a 2D array.\n",
    "confusion_matrix = tf.math.confusion_matrix(Y_test, test_predictions)\n",
    "\n",
    "# Use a heatmap plot to display it.\n",
    "ax = sns.heatmap(confusion_matrix, annot=True, fmt='.3g', cmap='Blues',\n",
    "                 xticklabels=label_names, yticklabels=label_names, cbar=False)\n",
    "\n",
    "# Add axis labels.\n",
    "ax.set(xlabel='Predicted Label', ylabel='True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-BrE8eaEw60"
   },
   "source": [
    "---\n",
    "### Exercise 2 (8 points)\n",
    "\n",
    "Answer the following questions by studying the confusion matrix (above).\n",
    "\n",
    "1. Which class has the lowest precision? What is that precision? Which class has the highest precision? What is that precision?\n",
    "\n",
    "2. For the class 'sneaker', what class is the largest source of false negatives? What about the largest source of false positives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfQfsvzpVwfK"
   },
   "source": [
    "*Written answer:*\n",
    "\n",
    "1. \n",
    "\n",
    "2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpFmB9v5V4CE"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epIqYiQhQpJC"
   },
   "source": [
    "## Analyze Errors\n",
    "\n",
    "A crucial part of the development cycle in Machine Learning is analyzing errors to help understand the shortcomings of the model. While typically we'd want to use the development data for this purpose to preserve the purity of the test set, we'll just use our test split for simplicity.\n",
    "\n",
    "Since the \"shirt\" class seems to be the source for a lot of errors, let's look at some of the confusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLK2zFv2SWAy"
   },
   "source": [
    "---\n",
    "### Exercise 3 (8 points)\n",
    "\n",
    "1. Display 5 images with true label \"shirt\", but predicted label \"coat\" (false negatives for the \"shirt\" class).\n",
    "2. Display 5 images with predicted label \"shirt\", but true label \"coat\" (false positives for the \"shirt\" class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xUZfCG1ylVtp"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCmcQmKXlYK7"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyMHf5pGjkxm"
   },
   "source": [
    "## Visualize Parameters\n",
    "Finally, here's some code that helps visualize the learned parameters for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "executionInfo": {
     "elapsed": 12395,
     "status": "ok",
     "timestamp": 1616042835746,
     "user": {
      "displayName": "Daniel Gillick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9DrSMlwYnG9EolecuJqe8n9m7fpcje4_UbYrhQ10=s64",
      "userId": "01872965353911650729"
     },
     "user_tz": 420
    },
    "id": "C-6ovDo8jvLH",
    "outputId": "9c2b3eac-bd32-4d3f-9e6c-3eade55f272f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights, biases = model.layers[1].get_weights()\n",
    "fig, axs = plt.subplots(2, 5, figsize=(16,7))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "  ax.imshow(weights[:,i].reshape(28,28), cmap='PRGn')\n",
    "  ax.axis('off')\n",
    "  ax.set_title(label_names[i])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN9qpWEqErz0SpDHvJfddfe",
   "name": "05 Multiclass Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
