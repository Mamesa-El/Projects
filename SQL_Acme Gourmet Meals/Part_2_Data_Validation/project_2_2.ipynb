{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f465500",
   "metadata": {},
   "source": [
    "# Project 2, Part 2, Parse Peak's sales JSON file into CSV files\n",
    "\n",
    "University of California, Berkeley\n",
    "\n",
    "Master of Information and Data Science (MIDS) program\n",
    "\n",
    "w205 - Fundamentals of Data Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c6e20e",
   "metadata": {},
   "source": [
    "# Included Modules and Packages\n",
    "\n",
    "Code cell containing your includes for modules and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "530d745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import json\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91c8869",
   "metadata": {},
   "source": [
    "# Supporting code\n",
    "\n",
    "Code cells containing any supporting code, such as connecting to the database, any functions, etc.  \n",
    "\n",
    "Remember you can freely use any code from the labs. You do not need to cite code from the labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e09ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# function to run a select query and return rows in a pandas dataframe\n",
    "# pandas puts all numeric values from postgres to float\n",
    "# if it will fit in an integer, change it to integer\n",
    "#\n",
    "\n",
    "def my_select_query_pandas(query, rollback_before_flag, rollback_after_flag):\n",
    "    \"function to run a select query and return rows in a pandas dataframe\"\n",
    "    \n",
    "    if rollback_before_flag:\n",
    "        connection.rollback()\n",
    "    \n",
    "    df = pd.read_sql_query(query, connection)\n",
    "    \n",
    "    if rollback_after_flag:\n",
    "        connection.rollback()\n",
    "    \n",
    "    # fix the float columns that really should be integers\n",
    "    \n",
    "    for column in df:\n",
    "    \n",
    "        if df[column].dtype == \"float64\":\n",
    "\n",
    "            fraction_flag = False\n",
    "\n",
    "            for value in df[column].values:\n",
    "                \n",
    "                if not np.isnan(value):\n",
    "                    if value - math.floor(value) != 0:\n",
    "                        fraction_flag = True\n",
    "\n",
    "            if not fraction_flag:\n",
    "                df[column] = df[column].astype('Int64')\n",
    "    \n",
    "    return(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d12068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(\n",
    "    user = \"postgres\",\n",
    "    password = \"ucb\",\n",
    "    host = \"postgres\",\n",
    "    port = \"5432\",\n",
    "    database = \"postgres\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6e2080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c57f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_read_csv_file(file_name, limit):\n",
    "    \"read the csv file and print only the first limit rows\"\n",
    "    \n",
    "    csv_file = open(file_name, \"r\")\n",
    "    \n",
    "    csv_data = csv.reader(csv_file)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for row in csv_data:\n",
    "        i += 1\n",
    "        if i <= limit:\n",
    "            print(row)\n",
    "            \n",
    "    print(\"\\nPrinted \", min(limit, i), \"lines of \", i, \"total lines.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c49b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_recursive_print_json(j, level = -1):\n",
    "    \"given a json object print it\"\n",
    "    \n",
    "    level += 1\n",
    "    \n",
    "    spaces = \"    \"\n",
    "    \n",
    "    if type(j) is dict:\n",
    "        dict_2_list = list(j.keys())\n",
    "        for k in dict_2_list:\n",
    "            print(spaces * level + k)\n",
    "            my_recursive_print_json(j[k], level)\n",
    "            \n",
    "    elif type(j) is list:\n",
    "        for (i, l) in enumerate(j):\n",
    "            print(spaces * level + \"[\" + str(i) + \"]\")\n",
    "            my_recursive_print_json(l, level)\n",
    "                  \n",
    "    else:\n",
    "        print(spaces * level + \"value:\", str(j))\n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daa274c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_read_nested_json(file_name):\n",
    "    \"given a file of json, read it and parse it meaningfully\"\n",
    "    \n",
    "    f = open(file_name, \"r\")\n",
    "    \n",
    "    j = json.load(f)\n",
    "    \n",
    "    f.close\n",
    "    \n",
    "    my_recursive_print_json(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e6beed",
   "metadata": {},
   "source": [
    "# 2.2.1 Recursive walk of Peak's sales JSON file to help understand the structure\n",
    "\n",
    "Peak has send AGM a nested JSON file of sales data for October 3, 2020.  We need to first understand the structure of this file so we can parse it into CSV files to load into staging tables.\n",
    "\n",
    "Use the function my_read_nested_json() which calls my_recursive_print_json() to take a recursive walk of the nested JSON file peak_sales_2020_10_03.json to help understand the structure.  These functions are from the lab, and are included above for your convenience.\n",
    "\n",
    "### Please take some time to study the structure until you understand it.  Understanding the structure will make it much easier to write the parsing code.\n",
    "\n",
    "Pattern your code after the examples in the labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd63b767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "my_read_nested_json() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_618/1299830859.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_read_nested_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"peak_sales_2020_10_03.json\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: my_read_nested_json() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "my_read_nested_json(\"peak_sales_2020_10_03.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e9dd0",
   "metadata": {},
   "source": [
    "# 2.2.2 Parse Peak's nested JSON sales file into CSV files\n",
    "\n",
    "Write Python code to parse Peak's nested JSON sales file, peak_sales_2020_10_03.json, into CSV files.\n",
    "\n",
    "The first line of each file should be a list of fields as specified below.\n",
    "\n",
    "Do NOT sort them.  Keep the csv data rows in the same order as the data appears in the JSON file.\n",
    "\n",
    "Do NOT remove duplicates.\n",
    "\n",
    "peak_sales.csv\n",
    "* sale_id - Peak's sale_id (NOT AGM's sale_id)\n",
    "* sale_date\n",
    "* sub_total - should equal the sum of line item quantity x 12\n",
    "* tax - should be 0 as our items are tax exempt\n",
    "* total_amount = sub_total + tax\n",
    "\n",
    "peak_stores.csv\n",
    "* sale_id - we need this to be able to link this to peak_sales\n",
    "* location_id - Peak's location_id (NOT AGM's store_id)\n",
    "* name  \n",
    "* street \n",
    "* city \n",
    "* state \n",
    "* zip \n",
    "\n",
    "peak_customers.csv\n",
    "* sale_id - we need this to be able to link this to peak_sales\n",
    "* customer_id - Peak's customer_id (NOT AGM's customer_id)\n",
    "* first_name\n",
    "* last_name\n",
    "* street\n",
    "* city\n",
    "* state\n",
    "* zip\n",
    "\n",
    "peak_line_items.csv\n",
    "* sale_id - we need this to be able to link this to peak_sales\n",
    "* line_item_id - you will need to sequentially number them within each sale starting with 1\n",
    "* product_id - Peak's product ID (NOT AGM's product_id)\n",
    "* price - should be 12\n",
    "* quantity\n",
    "* taxable - should be 'N' for not taxable\n",
    "\n",
    "After creating these CSV files, be sure and check them into your GitHub repo.\n",
    "\n",
    "Pattern your code after the examples in the labs. You may use as many code cells as you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f0c0fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"peak_sales_2020_10_03.json\", \"r\")\n",
    "j = json.load(f)\n",
    "f.close() \n",
    "\n",
    "sales_json_list = []\n",
    "peak_stores_json_list = []\n",
    "peak_customers_json_list = []\n",
    "peak_line_items_json_list = []\n",
    "\n",
    "for sales in j['sales']:\n",
    "    sales_json = {}\n",
    "    sales_json['sale_id'] = sales['sale_id']\n",
    "    sales_json['sale_date'] = sales['sale_date']\n",
    "    sales_json['sub_total'] = sales['sub_total']\n",
    "    sales_json['tax'] = sales['tax']\n",
    "    sales_json['total_amount'] = sales_json['sub_total'] + sales_json['tax']\n",
    "\n",
    "    sales_json_list.append(sales_json)\n",
    "\n",
    "    stores_json = {}\n",
    "    stores_json['sale_id'] = sales['sale_id']\n",
    "    stores_json['location_id'] = sales['pickup_from']['location_id']\n",
    "    stores_json['name'] = sales['pickup_from']['name']\n",
    "    stores_json['street'] = sales['pickup_from']['street']\n",
    "    stores_json['city'] = sales['pickup_from']['city']\n",
    "    stores_json['state'] = sales['pickup_from']['state']\n",
    "    stores_json['zip'] = sales['pickup_from']['zip']\n",
    "\n",
    "    peak_stores_json_list.append(stores_json)\n",
    "    \n",
    "    customeres_json = {}\n",
    "    customeres_json['sale_id'] = sales['sale_id']\n",
    "    customeres_json['customer_id'] = sales['deliver_to']['customer_id']\n",
    "    customeres_json['first_name'] = sales['deliver_to']['first_name']\n",
    "    customeres_json['last_name'] = sales['deliver_to']['last_name']\n",
    "    customeres_json['street'] = sales['deliver_to']['street']\n",
    "    customeres_json['city'] = sales['deliver_to']['city']\n",
    "    customeres_json['state'] = sales['deliver_to']['state']\n",
    "    customeres_json['zip'] = sales['deliver_to']['zip']\n",
    "    \n",
    "    peak_customers_json_list.append(customeres_json)\n",
    "    i = 1\n",
    "    for items in sales['line_items']:\n",
    "        line_items_json = {}\n",
    "        line_items_json['sale_id'] = sales['sale_id']\n",
    "        line_items_json['line_item_id'] = i\n",
    "        line_items_json['product_id'] = items['product_id']\n",
    "        line_items_json['price'] = items['price']\n",
    "        line_items_json['quantity'] = items['quantity']\n",
    "        line_items_json['taxable'] = items['taxable']\n",
    "        i = i+1\n",
    "        \n",
    "        peak_line_items_json_list.append(line_items_json)\n",
    "\n",
    "f = open(\"peak_sales.csv\", \"w\")\n",
    "dw = csv.DictWriter(f, sales_json_list[0].keys())\n",
    "dw.writeheader()\n",
    "dw.writerows(sales_json_list)\n",
    "f.close()\n",
    "\n",
    "f = open(\"peak_stores.csv\", \"w\")\n",
    "dw = csv.DictWriter(f, peak_stores_json_list[0].keys())\n",
    "dw.writeheader()\n",
    "dw.writerows(peak_stores_json_list)\n",
    "f.close()\n",
    "\n",
    "f = open(\"peak_customers.csv\", \"w\")\n",
    "dw = csv.DictWriter(f, peak_customers_json_list[0].keys())\n",
    "dw.writeheader()\n",
    "dw.writerows(peak_customers_json_list)\n",
    "f.close()\n",
    "\n",
    "f = open(\"peak_line_items.csv\", \"w\")\n",
    "dw = csv.DictWriter(f, peak_line_items_json_list[0].keys())\n",
    "dw.writeheader()\n",
    "dw.writerows(peak_line_items_json_list)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35faf850",
   "metadata": {},
   "source": [
    "# 2.2.3 Display the CSV file peak_sales.csv\n",
    "\n",
    "Use the function my_read_csv_file() from the labs (with a limit of 10) to display the CSV file you just created:\n",
    "* peak_sales.csv\n",
    "\n",
    "For your convenience the function is provided above.\n",
    "\n",
    "Pattern your code after the examples in the labs.\n",
    "\n",
    "The output should look similar to this:\n",
    "```\n",
    "['sale_id', 'sale_date', 'sub_total', 'tax', 'total_amount']\n",
    "['5763728874', '2020-10-03', '12', '0', '12']\n",
    "['5763729036', '2020-10-03', '72', '0', '72']\n",
    "['5763728904', '2020-10-03', '24', '0', '24']\n",
    "['5763728973', '2020-10-03', '96', '0', '96']\n",
    "['5763728757', '2020-10-03', '108', '0', '108']\n",
    "['5763729051', '2020-10-03', '144', '0', '144']\n",
    "['5763729153', '2020-10-03', '24', '0', '24']\n",
    "['5763728608', '2020-10-03', '96', '0', '96']\n",
    "['5763728696', '2020-10-03', '84', '0', '84']\n",
    "\n",
    "Printed  10 lines of  98 total lines.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ecda74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sale_id', 'sale_date', 'sub_total', 'tax', 'total_amount']\n",
      "['5763728874', '2020-10-03', '12', '0', '12']\n",
      "['5763729036', '2020-10-03', '72', '0', '72']\n",
      "['5763728904', '2020-10-03', '24', '0', '24']\n",
      "['5763728973', '2020-10-03', '96', '0', '96']\n",
      "['5763728757', '2020-10-03', '108', '0', '108']\n",
      "['5763729051', '2020-10-03', '144', '0', '144']\n",
      "['5763729153', '2020-10-03', '24', '0', '24']\n",
      "['5763728608', '2020-10-03', '96', '0', '96']\n",
      "['5763728696', '2020-10-03', '84', '0', '84']\n",
      "\n",
      "Printed  10 lines of  98 total lines.\n"
     ]
    }
   ],
   "source": [
    "my_read_csv_file('peak_sales.csv',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e885e55",
   "metadata": {},
   "source": [
    "# 2.2.4 Display the CSV file peak_stores.csv\n",
    "\n",
    "Use the function my_read_csv_file() from the labs (with a limit of 10) to display the CSV file you just created:\n",
    "* peak_stores.csv\n",
    "\n",
    "For your convenience, the function is provided above.\n",
    "\n",
    "Pattern your code after the examples in the labs.  \n",
    "\n",
    "The output should look similar to this:\n",
    "\n",
    "```\n",
    "['sale_id', 'location_id', 'name', 'street', 'city', 'state', 'zip']\n",
    "['5763728874', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "['5763729036', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "['5763728904', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "['5763728973', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "['5763728757', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "['5763729051', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "['5763729153', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "['5763728608', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "['5763728696', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "\n",
    "Printed  10 lines of  98 total lines.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e979ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sale_id', 'location_id', 'name', 'street', 'city', 'state', 'zip']\n",
      "['5763728874', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
      "['5763729036', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
      "['5763728904', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
      "['5763728973', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
      "['5763728757', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
      "['5763729051', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
      "['5763729153', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
      "['5763728608', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
      "['5763728696', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
      "\n",
      "Printed  10 lines of  98 total lines.\n"
     ]
    }
   ],
   "source": [
    "my_read_csv_file('peak_stores.csv',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a2ef6a",
   "metadata": {},
   "source": [
    "# 2.2.5 Display the CSV file peak_customers.csv\n",
    "\n",
    "Use the function my_read_csv_file() from the labs (with a limit of 10) to display the CSV file you just created:\n",
    "* peak_customers.csv\n",
    "\n",
    "For your convenience, the function is provided above.\n",
    "\n",
    "Pattern your code after the examples in the labs.\n",
    "\n",
    "The output should look similar to this:\n",
    "\n",
    "```\n",
    "['sale_id', 'customer_id', 'first_name', 'last_name', 'street', 'city', 'state', 'zip']\n",
    "['5763728874', '3728404', 'Darrelle', 'Dohrmann', '46 Farwell Terrace', 'Oakland', 'CA', '94609']\n",
    "['5763729036', '3729309', 'Moria', 'Greenwood', '8803 Delaware Crossing', 'Berkeley', 'CA', '94705']\n",
    "['5763728904', '3728508', 'Josiah', 'Hulett', '6755 Melby Plaza', 'Oakland', 'CA', '94612']\n",
    "['5763728973', '3728534', 'Gayle', 'MacGarrity', '286 Onsgard Center', 'Berkeley', 'CA', '94703']\n",
    "['5763728757', '3729188', 'Courtenay', 'Shirrell', '75 West Park', 'Emeryville', 'CA', '94608']\n",
    "['5763729051', '3729276', 'Christian', 'Anyene', '869 Transport Crossing', 'Berkeley', 'CA', '94707']\n",
    "['5763729153', '3729242', 'Linnell', 'Barr', '521 Fallview Alley', 'Oakland', 'CA', '94602']\n",
    "['5763728608', '3728705', 'Benedick', 'Staneland', '3852 Laurel Park', 'Berkeley', 'CA', '94704']\n",
    "['5763728696', '3729340', 'Lanni', 'Pickavant', '481 Moose Pass', 'Oakland', 'CA', '94609']\n",
    "\n",
    "Printed  10 lines of  98 total lines.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c22b7b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sale_id', 'customer_id', 'first_name', 'last_name', 'street', 'city', 'state', 'zip']\n",
      "['5763728874', '3728404', 'Darrelle', 'Dohrmann', '46 Farwell Terrace', 'Oakland', 'CA', '94609']\n",
      "['5763729036', '3729309', 'Moria', 'Greenwood', '8803 Delaware Crossing', 'Berkeley', 'CA', '94705']\n",
      "['5763728904', '3728508', 'Josiah', 'Hulett', '6755 Melby Plaza', 'Oakland', 'CA', '94612']\n",
      "['5763728973', '3728534', 'Gayle', 'MacGarrity', '286 Onsgard Center', 'Berkeley', 'CA', '94703']\n",
      "['5763728757', '3729188', 'Courtenay', 'Shirrell', '75 West Park', 'Emeryville', 'CA', '94608']\n",
      "['5763729051', '3729276', 'Christian', 'Anyene', '869 Transport Crossing', 'Berkeley', 'CA', '94707']\n",
      "['5763729153', '3729242', 'Linnell', 'Barr', '521 Fallview Alley', 'Oakland', 'CA', '94602']\n",
      "['5763728608', '3728705', 'Benedick', 'Staneland', '3852 Laurel Park', 'Berkeley', 'CA', '94704']\n",
      "['5763728696', '3729340', 'Lanni', 'Pickavant', '481 Moose Pass', 'Oakland', 'CA', '94609']\n",
      "\n",
      "Printed  10 lines of  98 total lines.\n"
     ]
    }
   ],
   "source": [
    "my_read_csv_file('peak_customers.csv',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d92221c",
   "metadata": {},
   "source": [
    "# 2.2.6 Display the CSV file peak_line_items.csv\n",
    "\n",
    "Use the function my_read_csv_file() from the labs (with a limit of 10) to display the CSV file you just created:\n",
    "* peak_line_items.csv\n",
    "\n",
    "For your convenience, the function is provided above.\n",
    "\n",
    "Pattern your code after the examples in the labs.  \n",
    "\n",
    "The output should look similar to this:\n",
    "\n",
    "```\n",
    "['sale_id', 'line_item_id', 'product_id', 'price', 'quantity', 'taxable']\n",
    "['5763728874', '1', '42314780', '12', '1', 'N']\n",
    "['5763729036', '1', '42314677', '12', '1', 'N']\n",
    "['5763729036', '2', '42314782', '12', '3', 'N']\n",
    "['5763729036', '3', '42314784', '12', '2', 'N']\n",
    "['5763728904', '1', '42314780', '12', '1', 'N']\n",
    "['5763728904', '2', '42314784', '12', '1', 'N']\n",
    "['5763728973', '1', '42314677', '12', '2', 'N']\n",
    "['5763728973', '2', '42314780', '12', '2', 'N']\n",
    "['5763728973', '3', '42314782', '12', '2', 'N']\n",
    "\n",
    "Printed  10 lines of  353 total lines.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bafbc2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sale_id', 'line_item_id', 'product_id', 'price', 'quantity', 'taxable']\n",
      "['5763728874', '1', '42314780', '12', '1', 'N']\n",
      "['5763729036', '1', '42314677', '12', '1', 'N']\n",
      "['5763729036', '2', '42314782', '12', '3', 'N']\n",
      "['5763729036', '3', '42314784', '12', '2', 'N']\n",
      "['5763728904', '1', '42314780', '12', '1', 'N']\n",
      "['5763728904', '2', '42314784', '12', '1', 'N']\n",
      "['5763728973', '1', '42314677', '12', '2', 'N']\n",
      "['5763728973', '2', '42314780', '12', '2', 'N']\n",
      "['5763728973', '3', '42314782', '12', '2', 'N']\n",
      "\n",
      "Printed  10 lines of  353 total lines.\n"
     ]
    }
   ],
   "source": [
    "my_read_csv_file('peak_line_items.csv',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c66c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
