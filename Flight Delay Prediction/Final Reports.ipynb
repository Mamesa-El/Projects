{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ad8fec7-585f-44b1-bac9-0354d2e3267a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Reducing United Airlines Flight Delays\n",
    "MIDS 261 Summer 2023 Final Project\n",
    "\n",
    "Section 2 Group 4 (Cluster team 2-1)\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd033a5d-984e-4aef-86cc-998dd8a26104",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Team Members\n",
    "\n",
    "| **Name** |  **Email**  |\n",
    "|:-----|:--------:|\n",
    "| Mamesa El | mamesa.el@berkeley.edu |\n",
    "| Sam Gupta| sambhav.gupta@berkeley.edu |\n",
    "| Sneha Narain | sn3ae@berkeley.edu |\n",
    "| Jonathan Tran | bk_pbjonmt@berkeley.edu |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64e7a7ac-d4b7-4f89-9ac3-eba248cdbf7c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Project Phase Leaders\n",
    "\n",
    "| **Phase #** | **Phase** |  **Person**  |\n",
    "|:-------|:--------:|:--------:|\n",
    "| 1 | Project Plan  | Sam |\n",
    "| 2 | EDA & Baseline Pipeline | Jonathan |\n",
    "| 3 | Feature Engineering and Hyperparameter Tuning | Sneha |\n",
    "| 4 | Algorithm Selection & Fine-Tuning | Mamesa |\n",
    "| 5 | Final Presentation | Sam |\n",
    "\n",
    "![test image]( /files/tables/image__9_.png)\n",
    "\n",
    "***Group Members (Left to Right)***: Jonathan, Sneha, Mamesa, Sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c46dcae0-a07c-4eb5-9657-25898ed2a605",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Gantt Chart for Project\n",
    "\n",
    "![test image7]( /files/tables/Screenshot_2023_07_17_at_5_48_17_PM.png)\n",
    "_** Phase 4 is across both July and August_\n",
    "\n",
    "<br>\n",
    "\n",
    "## Completed Assignments\n",
    "\n",
    "| **Phase #** | **Task** |  **Person(s)**  | Hours\n",
    "|:-------|:--------:|:--------:|:--------:\n",
    "| 1 | Abstract  | Sneha | 1 |\n",
    "| 1 | Data Description | Sneha, Jonathan, Sam | 2 |\n",
    "| 1 | Machine Learning Algorithms & Evaluation Metrics | Mamesa | 2 |\n",
    "| 1 | Machine Learning Pipelines  | Sneha, Sam, Mamesa | 1 |\n",
    "| 1 | General Phase 1 Formatting | All | 1 |\n",
    "| 1 | Credit Assignment Plan / [Rubric Coverage Google Doc](https://docs.google.com/spreadsheets/d/1L-qje4EYnVbV9TaiupFTxaTmk1kbf9S0UP9npvnTmwk/edit#gid=0) | Jonathan, Sam | 1|\n",
    "|1 | Conclusion and Next Steps | Jonathan| 0.5 |\n",
    "| 2 | EDA - Feature Viz  | Mamesa, Sam | 4 |\n",
    "| 2 | EDA - Correlation | Mamesa, Sam | 2 |\n",
    "| 2 | Feature Engineering - Selection  | Mamesa, Sneha | 4 |\n",
    "| 2 | Feature Engineering - Data Type Cleanup / Null Handling  | Mamesa, Sam, Sneha | 8 |\n",
    "| 2 | Feature Engineering - Creation | Jonathan | 0.5 |\n",
    "| 2 | Baseline Pipeline | Jonathan, Mamesa | 6 |\n",
    "| 2 | Baseline Model  | Jonathan, Mamesa | 8 |\n",
    "| 2 | Credit Assignment Plan & Task Allocation / [Rubric Coverage Google Doc](https://docs.google.com/spreadsheets/d/1L-qje4EYnVbV9TaiupFTxaTmk1kbf9S0UP9npvnTmwk/edit#gid=0) | All| 2 |\n",
    "| 2 | Conclusion and Next Steps | All | 0.5 |\n",
    "| 2 | Slideshow - Main Presentation | Sam| 3 |\n",
    "| 2 | Slideshow - 2 minute | Sam| 0.5 |\n",
    "| 3 | Feature Engineering - Creation  | Sam | 4 |\n",
    "| 3 | Feature Engineering - PCA  | Jonathan | 4 |\n",
    "| 3 | Feature Engineering - Null Handling | Jonathan | 0.5 |\n",
    "| 3 | Feature Engineering - Downsampling | Mamesa, Jonathon | 2 |\n",
    "| 3 | Time Series Cross Validation | Mamesa, Sneha | 6 |\n",
    "| 3 | Pipeline Remodeling | Jonathan | 6 |\n",
    "| 3 | Hyperparameter Tuning | All | 20 |\n",
    "| 3 | Conclusion and Next Steps | All | 0.5 |\n",
    "| 3 | Office Hours Questions for Vini | Jonathan, Sam| 1 |\n",
    "| 3 | Credit Assignment Plan & Task Allocation / [Rubric Coverage Google Doc](https://docs.google.com/spreadsheets/d/1L-qje4EYnVbV9TaiupFTxaTmk1kbf9S0UP9npvnTmwk/edit#gid=0) | Sneha | 2 |\n",
    "| 4 | Algorithm Selection | All | 1 |\n",
    "| 4 | Bootstrapping Method | Jonathan | 4 |\n",
    "| 4 | ML Flow Setup | Mamesa, Jonathan | 2 |\n",
    "| 4 | Fine Tuning - Logistic Regression | Mamesa | 4 |\n",
    "| 4 | Fine Tuning - Random Forest | Sam | 4 |\n",
    "| 4 | Fine Tuning - XGBoost | Jonathan | 4 |\n",
    "| 4 | Fine Tuning - Multilayer Perceptron | Sneha | 4 |\n",
    "| 4 | Presentation Slides | Sam | 3 |\n",
    "| 4 | 2 Minute Video | All | 0.5 |\n",
    "| 4 | Creating Report | All | 5 |\n",
    "| 4 | Credit Assignment Plan & Task Allocation / [Rubric Coverage Google Doc](https://docs.google.com/spreadsheets/d/1L-qje4EYnVbV9TaiupFTxaTmk1kbf9S0UP9npvnTmwk/edit#gid=0) | All| 2 |\n",
    "\n",
    "<br>\n",
    "\n",
    "## Credit Assignment Plan\n",
    "\n",
    "| **Phase #** | **Task** | **Person(s)**  |\n",
    "|:-------|:--------:|:--------:|\n",
    "| Phase 1 | Setup Azure <br> Run Setup Notebooks <br> Write Abstract <br> Data Descrption <br> ML Algorithms & Evaluation Metrics <br> ML Pipelines  <br> Credit Assignment Plan| All <br> All <br> Sneha <br> Jonathan, Sam, Sneha <br> Mamesa <br> All <br> Jonathan, Sam|\n",
    "| Phase 2 | EDA - Viz <br> EDA - Correlation <br> Baseline pipeline <br> Baseline model <br> Data cleaning <br> Feature Engineering - Selection <br> Feature Engineering - Data Cleanup and Null Handling <br> Feature Engineering - Creation <br> One hot encoding / categorization <br> Data Checkpoint <br> Slide show, video editing and recording | Mamesa, Sam  <br> Mamesa, Sam  <br> Jonathan , Mamesa <br> Jonathan , Mamesa <br> Mamesa , Sam , Sneha <br> Mamesa , Sneha  <br> Mamesa , Sam , Sneha <br> Jonathan  <br> Jonathan <br> All <br> Sam  |\n",
    "| Phase 3 | Feature Engineering - Creation <br> Feature Engineering - PCA <br> Feature Engineering - Null Handling <br> Feature Engineering - Downsampling <br> Time Series Cross Validation <br> Pipeline Remodeling <br> Hyper Parameter Tuning | Sam <br> Jonathan <br> Jonathan <br> Mamesa, Jonathan <br> Mamesa, Sneha <br> Jonathan <br> All |\n",
    "| Phase 4 | Algorithm Selection <br> Bootstrapping Method <br> Fine Tuning <br> Create Report <br> Prepare Presention <br>  Mock presentation <br> Cleanup Final Submission Notebook(s)  | All <br> Jonathan <br> All <br> All <br> Sam <br> All <br> All |\n",
    "\n",
    "_** Credit Assignment Plan may changes and project progresses_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d57f288f-d21a-42e8-9d98-349a562b4c20",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# US Flight Delay Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5b3def8-75bd-4721-9f41-446dde0fdc2c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7887f5a-27f8-4174-88ae-6d981d2d2617",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1.1 Business Case\n",
    "Flight delays pose a significant challenge within the airline industry, affecting both passengers' travel experiences and airlines' operational efficiency. As representatives of United Airlines, we recognize that mitigating flight delays is not only crucial for ensuring a smooth journey for our customers but also for maintaining our reputation and optimizing resources. According to data from the _Bureau of Transportation Statistics (BTS)_, approximately **22.09% of United flights experienced delays in 2023**. These delays can lead to financial losses, customer dissatisfaction, and operational disruptions, making it imperative for us to take proactive steps to address this issue.\n",
    "\n",
    "Our project aims to predict flight delays accurately and enable United Airlines to take preemptive measures to minimize their impact. By understanding historical flight data, we can identify patterns, trends, and contributing factors that lead to delays. This knowledge equips us to make informed decisions that can significantly improve operational efficiency and customer satisfaction.\n",
    "\n",
    "Our approach consists of a well-defined **four-step pipeline: data ingestion, data processing, data modeling, and model evaluation**. We start by gathering and preprocessing data, ensuring that it's clean, accurate, and ready for analysis. We then engineer relevant features that capture intricate relationships between variables, enhancing the predictive power of our models.\n",
    "\n",
    "In the data modeling phase, we deploy a range of machine learning algorithms including **(1) Logistic Regression, (2) Random Forest, (3) XGBoost, and (4) Multilayer Perceptron**. We evaluate these models using a suite of performance metrics, including **Accuracy, Precision, Recall, F1-score, AUC, and PR curve**. These metrics provide a comprehensive understanding of the models' strengths and weaknesses, helping us select the most effective approach for our predictive tasks. The primary metric we will be using to evaluate our model is the **F1-score** because it combines elements of both precision and recall while being effective for imbalance datasets.\n",
    "\n",
    "The implications of implementing a successful predictive model for flight delays are far-reaching. By accurately anticipating potential delays, United Airlines can take proactive steps to minimize disruptions. For instance, adjusting crew schedules, gate assignments, and maintenance activities can help us optimize resources and mitigate the cascading effects of delayed flights. This directly translates to significant cost savings and operational efficiencies.\n",
    "\n",
    "In addition to operational benefits, our predictive model has the potential to greatly enhance customer satisfaction. By proactively informing passengers of potential delays, United Airlines can offer alternative travel arrangements, accommodations, and amenities, fostering a positive experience even in challenging situations. Meeting and exceeding customer expectations can boost loyalty and solidify our brand reputation.\n",
    "\n",
    "While our project addresses the pressing issue of flight delays, it also lays the foundation for ongoing improvements. Future iterations could incorporate real-time data streaming, enabling real-time predictions and responsive decision-making. Furthermore, refining our models through more advanced techniques such as deep learning and ensemble methods could potentially unlock even greater predictive accuracy.\n",
    "\n",
    "Our project holds the promise of transforming how United Airlines approaches and mitigates flight delays. By combining cutting-edge data analytics, machine learning, and a customer-centric mindset, we aim to revolutionize the air travel experience. Through this initiative, United Airlines can proactively reduce costs, optimize operations, and deliver exceptional service, reaffirming our commitment to excellence in the aviation industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97387cd0-8692-4d46-93b5-b79946cf9cbc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1.2 Abstract\n",
    "\n",
    "Flight delays profoundly impact the airline sector, touching both customers and service providers.\n",
    "\n",
    "In 2023, data from the _Bureau of Transportation Statistics (BTS)_ highlighted that **22.09% of United flights experienced delays**. Such postponements not only strain finances but also tarnish brand images and amplify customer grievances. At United Airlines, our mission revolves around accurately forecasting delays for domestic US flights. For the last phase of the study, the feature engineering pipeline was revised and streamlined and the models were trained and hypertuned using the 60 month dataset. The two highest performing models were **XGBoost**, showcasing an **F1 score** of **78.3%**, and **Multilayer Perceptron**, which scored **74.9%**. XGBoost was chosen as the final model for its built-in management of class imbalances, low runtime, and high F1 score, which was **77.2%** using the held-out dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8db7519e-37c3-4eed-886c-d528809de9a8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2. Data Description\n",
    "\n",
    "The datasets utilized for this study are *OTPW_3m_2015*, *OTPW_12W_2015*, and *OTPW_60M*. All three of these datasets were created from joining the the following datasets: flight, weather, and station datasets. The flight dataset was obtained from the [US Department of Transportation](https://www.transtats.bts.gov/Fields.asp?gnoyr_VQ=FGJ) and contains flight information from 2015 to 2021 ([Link to data dictionary](https://www.transtats.bts.gov/Fields.asp?gnoyr_VQ=FGJ)). The weather dataset was obtained from the [National Oceanic and Atmospheric Administration repository](https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.ncdc:C00679) and contains weather information from 2015 to 2021 ([Link to data dictionary](https://www.ncei.noaa.gov/data/global-hourly/doc/isd-format-document.pdf)). The stations dataset was obtained from the US Department of Transportation. This data was provided through [Berkeley MIDS](dbfs:/mnt/mids-w261/datasets_final_project_2022/stations_data).\n",
    "\n",
    "The *OTPW_3m_2015* dataset was used for EDA, Feature Engineering, and Hyperparameter Tuning in order to reduce runtime of these phases. It is composed of approximately **1,401,363 rows** and **216 columns**; however, after the feature engineering phase, the dataset consisted of **1,401,363 rows** and was reduced to **103 features**.\n",
    "\n",
    "The *OTPW_12W_2015* dataset was also used for EDA, Feature Engineering, and Hyperparameter Tuning in order to reduce runtime of these phases. It is composed of approximately **5,811,854 rows** and **216 columns**; however, after the feature engineering phase, the dataset consisted of **5,811,854 rows** and was reduced to **109 features**.\n",
    "\n",
    "Once all the features and hyperparameters were finalized, the *OTPW_60M* dataset was then utilized to obtain the final model results. It is composed of approximately **12,926,912 rows** and **216 columns**; however, after the feature engineering phase, the dataset consisted of **12,926,912 rows** and was reduced to **109 features**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25dbbc7b-5b1a-4fda-8c26-fc15fc0f972d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3. Issues Addressed\n",
    "There were many challenges that occurred during the execution of this study including data leakage, performance, scalability, and imbalanced data. The issues and how they were addressed are documented below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ac10e74-b270-4e1f-8796-dddbb289bf19",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3.1 Data Leakage\n",
    "Data leakage occurs when information from outside the training dataset is used to create the model. As a result, this additional information can allow the model to learn something it would not otherwise know and falsely improve the model's performance. This can occur when onehot encoding and/or feature standardization is done on the entirety of the dataset rather than just the training set. In order to minimize data leakage, the following solutions were implemented as part of the model pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86cfcdc3-0967-4a18-aa1c-d33ae034b1e8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3.1.1 Avoiding Duplicates\n",
    "In some datasets, data leakage can occur when there is duplicate rows in the dataset. For example, one row can end up in the training set while the other duplicate is in the test set; therefore, the model will have a falsely increased performance on the test set. This, however, is not an issue for the datasets utilized in this study because each row represents a departing flight and if two rows were identical, then that would indicate that the same flight is departing twice at the exact same departure time, which is impossible. Thus, there is no possibility of data leakage occurring through this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9affd012-31e7-48a7-973f-f90d6ed52481",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3.1.2 K Fold and Time Series Cross Validation\n",
    "\n",
    "**K Fold** is the process of splitting the data into k parts and each part is then utilized for cross-validation, where performance is measured for each fold and then the average of all the folds are utilized to determine model performance. In most cases, standard cross validaton is sufficient enough to handle data leakage; however, the *OTPW_3m* datasets are all time-based datasets. Standard cross validation takes random samples from the dataset and assigns them to the train or test sets; however, in time series, utilzing random samples would lead to data leakage since future data points should not predict data points that occurred prior to it (_i.e. a flight on March 6, 2015 should not predict a flight on January 2, 2015_). To resolve this issue, **time series cross validation** must be utilized as it accounts for the temporal dimension of the data by preserving the order of the dataset.\n",
    "\n",
    "For our time series validation, we used **3 folds** that were ordered chronogically to avoid data leakage. Because of the chronogical ordered, the training set always consists of data occuring before the validation set. We created a separate feature engineering notebook to build our folds to optimize runtime. Ultimately, we tested our final model on a 3-fold blocking time series split to ensure that our model was not heavily impacted by data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8004c65f-60d4-4959-b3fb-1b709229925e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### 3.1.2a Bootstrapping\n",
    "\n",
    "As mentioned in the the data leakage description, data leakage can occur when StandardScalar or OneHot encoding is applied to the entire dataset rather than after splitting into training/test/validation sets. However, in order to improve the performance of data preprocessing and feature engineering, a study was conducted to see whether applying imputation, standard scaling, and PCA outside the k folds would lead to data leakage. This was done through a **bootstrapping method**, which is a resampling technique that repeatedly draws samples for the source dataset with replacement.\n",
    "\n",
    "The strategy was to randomly sample rows from the 12 month dataset and compare the mean and standard deviation for each sample. If the distribution of the mean and standard deviations were relatively similary, then it could be argued that applying StandardScalar to the entire dataset as opposed to each fold would be acceptable since the ability easily iterate models with minimal data leakage was a worthwhile tradeoff due to limited resources and time constraints.\n",
    "\n",
    "A similar bootstrapping method was utilized to verify that applying PCA outside of the pipeline did not affect the ability to maintain the dataset's variance. Another bootstrapping method was applied after StandardScalar and then the elbow method was applied to check the cumulative sum of each pricipal component. Based on the aggregation of these inputs, the optimal number of principal components to apply across the dataset was 7, while still maintaining over 75% of the dataset's variance. The output of the elbow method for a single model plot is shown below.\n",
    "\n",
    "![Graph 4](files/tables/ml_pipeline/Elbow_Method.png)\n",
    "\n",
    "**Figure 1:** PCA Elbow Method Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45fc3f13-66d6-4275-a3c1-2e2ac8137da5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3.2 Performance\n",
    "Due to the size of the dataset and the tight deadline of the study, performance had to be taken into account in order to produce results in a timely manner. To achieve this, tools such as **parquet** files and **MLFlow** were utilized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d71e33d-9ba1-45d1-8c66-af49f2529fcd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3.2.1 Parquet File Format\n",
    "\n",
    "All the datasets were formatted as parquet files. A **parquet file** is an open-source, column-oriented file format provided by Apache. It utilizes gzip compression for storage and due to its columnar nature, it stores each column's values as well as summary statistics together on a disk, which makes querying for columns quicker. Therefore, using a parquet is more efficient to store and process than a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5e384b0-bb0e-4e4e-b115-931baf3c7714",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3.3 Scalability\n",
    "Similar to performance, scalability had to be taken into account in order to effectively process the data. Tools such as **Databricks** and **MLFlow** provide tools for scalability, which in turn improved the performance and runtime of the code. Furthermore, these tools also provide the ability to save tables and models created from this study, which can then be utilized in future work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f68de5f-c178-48c0-9f6a-158b848ae436",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3.3.1 Databricks\n",
    "The Databricks platform was used to implement the entirety of the pipeline. **Databricks** is an open analytics platform that provides a unified interface and tools to build, deploy, maintain, and share data processing and analytics at scale. Databricks provides storage and memory resources via a cluster, which can be scaled dynamically. It provides code notebooks where users can work in various languages (_i.e. SQL, Spark, Python, etc._) to implement their data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbc2e06b-3041-45db-86af-0ca858266a89",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3.3.2 MLFlow\n",
    "MLFlow was utilized to build and deploy all 4 models trained in this study. **MLFlow** is an open-source tool for managing the machine learning lifecycle, which includes building, training, deploying, and updating the model. MLFlow provides the ability to hypertune the models and saves the result of each model to storage, which can be re-deployed as needed. This not only makes it easier to redeploy models in other notebooks, but also saves time by eliminating the need to re-run the entire model pipeline to regenerate the model. Furthermore, the experiments table provided by MLFlow made it easier to asses what the optimal hyperparameters and the highest metrics obtained were."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1ad68c5-a42f-4b45-bc4d-caf284a4a020",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3.4 Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ef2aa43-0c00-473e-9527-17880202cf60",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3.4.1 Down Sampling\n",
    "\n",
    "Initially we tried to improve model performance by using downsampling to create a 50:50 class balance. We chose to downsample rather than upsample because we felt this could help us lower our run time. However, downsampling resulted in worse performance. It's likely that a 50:50 class balance was not the ideal ratio. If given additional time, adjusting for optimal class balance would be a next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6514d958-91d8-4b76-bdd4-bab725c7ca66",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3.4.2 Hyper Parameter Tuning\n",
    "\n",
    "Although downsampling was not successful, we were able to improve our model performance by utilizing hyperparameters specifically for handling class imbalance. For example, with the XGB model, we were able to achieve a higher F1 score by improving the balance between precision and recall using the ```scale_pos_weight```. Using hyperparameters is not optimal because it cannot be applied to every model the same way, it would be preferrable to perform resampling before modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06ce7758-1cda-42d4-8930-de0efbfa5ddb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 4. Data Pipeline Overview\n",
    "The pipeline for our Machine Learning Pipeline is described and visualized below. For more information about feature families, please reference _**Section 6 Feature Engineering**_ and _**Section 7 Algorithms**_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9fe4d098-0eeb-40fa-b93e-477e9bd7a955",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Block Diagram of Machine Learning Pipeline\n",
    "![test image3]( /files/tables/Screenshot_2023_07_17_at_5_52_26_PM.png)\n",
    "<br>\n",
    "<br>\n",
    "**Figure 2**: Block Diagram of Machine Learning Pipeline showing data ingestition, data processing, modeling and deployment process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7629521-c813-4b7b-b13c-34681f4d9c7d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Workflow Diagram \n",
    "![pipeline](files/tables/Screenshot_2023_08_08_at_7_58_41_PM.png)\n",
    "<br>\n",
    "<br>\n",
    "**Figure 3**: This is a pipeline diagram displaying data ingestation, data wrangling, feature engineering, modeling, and cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cce6c6a6-3b2f-4499-9fcd-ff38852c0b13",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 5. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "918ff360-4801-4f25-a703-0fda91429e4e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5.1 Figure 4: All Flights vs. Delayed Flights By Day of the Week (3 Month, 12 Month, 60 Month)\n",
    "\n",
    "The visualization depicted below illustrates the cumulative flight delays across a three-month dataset across different days of the week. **Figure 4** presents a stacked bar plot from a 60-month dataset. Throughout the three-month datasets, Saturday consistently maintains the lowest total flight counts. In this dataset, Friday takes the lead with the highest delay rate at **19.5%**.\n",
    "\n",
    "In the 3 month visualzation, which is located in **_Appendix A.2.1 Flights VS Delay Flights by Day of the Week_**, flight distribution remains relatively even on weekdays, with Friday registering the highest flight counts and Saturday the lowest. In this dataset, Sunday stands out with the highest delay rate at **21.6%**, attributed to a higher ratio of delayed flights compared to the total flight count on that day.\n",
    "\n",
    "In the 12 month visualzation, which is located in **_Appendix A.3.1 Flights VS Delay Flights by Day of the Week_**, the stacked bar plot highlights the harmony between total flight counts and delay counts across all days within the 12-month dataset, excluding Saturday with its consistently lower total flight count. Notably, Monday and Thursday emerge with the highest delay rates, with Monday slightly surpassing at **19.1%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e536a3f-a4c9-474b-8618-85a7d6cc565a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "![DOW_delay_3m](files/tables/Delay_Flight_DOW_60m.png)<br/>\n",
    "**Figure 4**: A stacked bar plot of all flights vs delay flights by day of week for 60 months dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "107f8580-97ea-4097-a180-9d4e7c856e21",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5.2 Figure 5: All Flights vs Delayed Flights by Airline \n",
    "\n",
    "This visualization is a stacked bar plot that visualizes the number of flight delays from the total number of flights per airline. **Figure 5** offers insight into Frontier Airlines, which remains prominent with a peak delay rate of **24.7%**. In contrast, Hawaiian Airlines maintains a consistently low delay rate of **8%**. Remarkably, Frontier and Spirit Airlines consistently exhibit higher delay rates, while Hawaiian Airlines maintains its  consistently for low delay rate across all three datasets.\n",
    "\n",
    "In the 3 month visualzation, which is located in **_Appendix A.2.2 Flights VS Delay Flights by Airline_**, Southwest Airlines consistently leads in total flight counts across all datasets. Notably, Frontier Airlines records the highest delay rate at **31%**, whereas Alaska Airlines maintains the lowest delay rate at **1%** delays.\n",
    "\n",
    "In the 12 month visualzation, which is located in **_Appendix A.3.2 Flights VS Delay Flights by Airline_**, Spirit Airlines emerges with the highest delay rate at **27%**, whereas Hawaiian Airlines exhibits the lowest delay rate at **7%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3435efb2-7100-4a45-a53d-0e96bddba14d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "![DOW_delay_3m](files/tables/Screenshot_2023_08_07_at_6_07_29_PM.png)<br/>\n",
    "**Figure 5**: A stacked bar plot of all flights vs delay flights by airline for 60 months dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e266f22-aefc-4de9-8367-8281ed002ba9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5.3 Figure 6: Delays by Airport Heatmap\n",
    "This heatmap provides a visual representation of departure delays across various airports in mainland United States. Airports on the east and west coasts, especially those in California which are major international airports, appear to experience higher rates of flight delays. The intensity of the colors on the map signifies the frequency and severity of departure delays at these airports. Notably, O'Hare Airport in Chicago appears to have the most significant departure delay, indicated by its pronounced red hue on the interactive heatmap (interactive map in EDA notebook listed under Section 10 Relevant Notebooks.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d59920d9-651e-44ba-b1bb-565949034139",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "![graph 5](files/tables/Geo_Heat_Map.png)\n",
    "\n",
    "**Figure 6:** Geographic Heatmap of Flight Delays by Airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "402d8038-fdd2-40f0-b785-6158066862f3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5.5 Table 1: Delayed Routes\n",
    "This table provides insight into the top 10 delayed routes over 60 months. This table looks at the routes specifically due to flight numbers for routes that keep changing as well as tail numbers for airlines. With these changing variables the flight route by airline is the best metric to identify which connections have the most delays and what are the average delay times for these routes. By identifying the top 10 routes, aircraft models used on these flights can be identified to understand various additional information such as passenger capacity or even aircraft age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b7d5858-6d91-4f8a-8a0a-60aaa2707d2e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "![table 1](files/tables/Screenshot_2023_08_08_at_11_34_51_AM.png)\n",
    "\n",
    "**Table 1:** Top 10 Delayed Routes over 60 Months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95ed0b12-bfd9-4d68-af0d-0a9fd3417483",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 6. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35c25062-0763-4e12-bba4-b56b12fd9713",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6.1 Data Lineage \n",
    "The data lineage flowchart illustrates key data transformations, transitioning from the original dataset to the OTPW dataset. This latter set is then processed through feature engineering to derive the final dataset.  Additional information on key data transformations can be found in **Tables 2 and 3** under section **_6.2 Feature Creation_**.\n",
    "\n",
    "![Data Lineage](files/tables/image__7_.png)<br/><br/>\n",
    "**Figure 7**: Data Lineage Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8027cc0-196b-41c6-9e8c-731ed872b265",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6.2 Feature Creation and Selection\n",
    "\n",
    "25 new features were created during the feature engineering phase. Out of the **25 features**, **16** are **numeric**, **4** are **categorical**, and **5** are **graph** based. The features are listed in the tables below along with their respective EDAs. Note that not all the features created were used in the final dataset. The features that were chosen and utilized in the models are located in _**Table 3: Summary of Feature Families**_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85a7e38d-95f0-4615-a7f3-40e0a78b1051",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 6.2.1 Feature Creation Summary\n",
    "\n",
    "The table below lists all the features that were created and explored during the feature engineering section, which is a total of **25**. There are **3 feature types**: categorical (label-based data), numeric (number-based data), and graph. \n",
    "\n",
    "| **Feature Count** | **Feature Type** |  **Feature Name**  | Description\n",
    "|:-------|:--------:|:--------:|:--------:\n",
    "| 1 | Categorical  | DISTANCE_BIN | Categorize flight distance into bins (short, medium, and long-haul) |\n",
    "| 2 | Categorical | DIRECTION | Categorize flight direction based on origin and destination airport coordinates |\n",
    "| 3 | Numeric | AVG_DELAY_BY_AIRLINE | Calculate average delay by airline |\n",
    "| 4 | Numeric | AVG_DELAY_BY_DAY_OF_WEEK | Calculate average delay by day of the week |\n",
    "| 5 | Numeric | AVG_DELAY_BY_ORIGIN_DEST | Calculate delay by route |\n",
    "| 6 | Numeric | CARRIER_ORIGIN_AIRPORT_FLIGHT_FREQUENCY | Calculate flight frequency by airline and airport |\n",
    "| 7 | Numeric | FLIGHT_COUNT_BY_ORIGIN_DEST | Count number of flights by origin and destination |\n",
    "| 8 | Numeric | DELAY_RATIO | Calculate delay ratio |\n",
    "| 9 | Numeric | FLIGHT_FREQUENCY_BY_DAY | Calculate flight frequency by day of the week |\n",
    "| 10 | Numeric | FLIGHTS_BY_DIRECTION | Calculate the number of flights for each carrier in each direction |\n",
    "| 11 | Numeric | AVG_DISTANCE_BY_DIRECTION | Calculate the average distance of flights for each carrier in each direction |\n",
    "| 12 | Numeric | AVG_AIR_TIME_BY_DIRECTION | Calculate the average air time of flights for each carrier in each direction |\n",
    "| 13 | Numeric | AVG_DELAY_RATIO_BY_DIRECTION | Calculate the average delay ratio for each carrier in each direction |\n",
    "| 14 | Numeric | DEPARTURE_TEMP, ARRIVAL_TEMP, DEP_MAX_TEMP, DEP_MIN_TEMP | Average, maximum, and minimum temperature during departure and arrival times |\n",
    "| 15 | Numeric | DEPARTURE_PRECIP, ARRIVAL_PRECIP | Total precipitation amount during departure and arrival times |\n",
    "| 16 | Numeric | DEPARTURE_WIND_SPEED, ARRIVAL_WIND_SPEED | Average wind speed during departure and arrival times |\n",
    "| 17 | Numeric | DEPARTURE_VISIBILITY, ARRIVAL_VISIBILITY | Average visibility during departure and arrival times |\n",
    "| 18 | Categorical | flight_time_category | Categorize time of day for flight departures |\n",
    "| 19 | Graph | AIRPORT_CONNECTIVITY | Number of direct flights from each airport to other airports |\n",
    "| 20 | Graph | AIRPORT_DEGREE_CENTRALITY | Measure the importance of an airport based on the number of connections it has |\n",
    "| 21 | Graph | FLIGHT_DENSITY | Number of flights at each airport |\n",
    "| 22 | Graph | AVG_FLIGHT_DISTANCE | Average flight distance from each airport |\n",
    "| 23 | Graph | FLIGHT_FREQUENCY_BY_AIRLINE | Calculate the frequency of flights for each airline |\n",
    "| 24 | Numeric | previous_flightnum_delay_ct | Calculate the number of delays of each flight number over a rolling window |\n",
    "| 25 | Categorical | us_holiday | Categorize if the flight took place during a U.S. Holiday |\n",
    "\n",
    "**Table 2**: Summary of New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "639868fc-879b-4821-acce-4e2664d3f8db",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 6.2.2 Feature Families\n",
    "The table below breaks down all the newly created features into feature families. There are **3 feature families**: weather metrics, flight details, and miscallaneous. \n",
    "| **Feature Family** | **Numeric Features** | **Numeric PCA Features** | **Categorical** | **Description** | **Row Total** | \n",
    "|:-------|:--------:|:--------:|:--------:|:--------:|:--------:\n",
    "| Weather Metrics | <ul><li>HOURLYWINDSPEED</li><li>HOURLYVISIBILITY</li><li>HourlyDryBulbTemperature</li><li>HourlyWindDirection</li></ul>| <ul><li>HourlyWetBulbTemperature</li><li>HourlyRelativeHumidity</li><li>HourlyPrecipitation</li><li>HourlyAltimeterSetting</li><li>HourlyPressureChange</li> <li>HourlyWindGustSpeed</li> <li>DailyPeakWindSpeed</li> <li>DailySnowDepth</li> <li>DailySnowfall</li> <li>DailySustainedWindSpeed</li> <li>DailyMinimumDryBulbTemperature</li> <li>DailyAverageRelativeHumidity</li> <li>DailyMaximumDryBulbTemperature</li></ul> |  | This family of data consists of weather metrics, encompassing a set of features that offer measurements related to wind speed, humidity levels, and temperature. | 17 |\n",
    "| Flight Details | <ul><li>AIRTIME</li><li>previous_flightnum_delay_ct</li> | <li>DISTANCE</li> | <ul><li>FLIGHT_TIME_CATEGORY</li><li>DAY_OF_WEEK</li><li>OP_CARRIER_AIRLINE_ID | This dataset family comprises flight-related metrics, including flight times (including delays) and dates, flight distances, and flight number details.  | 6 |\n",
    "| Misc |  |  | <ul><li>REPORT_TYPE | This an ID that identifies the type of weather report. | 1 |\n",
    "| Column Total| 6 | 14 | 4 |  | 24 | \n",
    "\n",
    "**Table 3**: Summary of Feature Families"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6224fa8a-57c1-49ac-ad08-91fc21303460",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 6.2.3 Feature Importance\n",
    "A feature importance plot was generated on the 3 month dataset after running it through the Feature Engineering pipeline using the ```feature_importance``` function. The feature that scored the highest was *features_numeric_non_pca_scaled_5*, which correlates with the feature *previous_flightnum_delay_ct*. The second and third highest features were *HourlyDryBulbTemperature* and *flight_time_category_class_Night*, respectively.\n",
    "\n",
    "![Graph 4](files/tables/Screenshot_2023_08_08_at_9_16_23_PM.png)<br/>\n",
    "**Figure 8**: A feature importance graph of the features that were fed into vector assembler and their corresponding importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83b753f4-d517-4b97-ae17-53a10d20cf09",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6.3 Null Handling\n",
    "Null values were handled through a combination of dropping and imputing. Imputation is the process of utilizing statistical methods (_i.e. mean, mode, median_) to estimate the value of a feature and then replace the nulls with said value. In this study, any feature with over 1 million nulls were dropped from the dataset; however, any null value in the rows of the remaining numeric and categorical features were imputed. For the categorical features, the nulls were filled with a string value and for the numeric features, they were replaced with the corresponding mean (average) value of the feature using the PySpark ```Imputer``` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee36721f-c4b8-4a59-8e04-5ecd9460b72d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6.4 Standard Scaling\n",
    "The dataset is comprised of various numerical features, which are not measured in the same scales. As a result, they may not contribute equally to the training and fit of the model, which may lead to a bias in the final model. In order to combat this issue, standard scaling was applied to all the numerical features in the training set. Standard scaling removes the mean and scales the data to the unit variance and this was done using the Pyspark ```StandardScaler``` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f181c833-8e04-481a-b1b9-3601fb2a678f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6.5 Principal Component Analysis (PCA)\n",
    "PCA is an unsupervised learning technique that it utilized to reduce dimensionality of the data. When PCA is applied, it helps determine the number of features that the dataset can be reduced to while still retaining the explainability of the original dataset. This was done using the PySpark ```PCA``` function, where a large set of variables are transform into a smaller set of variable and still retain its most of its information in the larger set. An additional benefit of PCA is that it can also improve model run times through reducing the number of features processed in the model.\n",
    "<br/>\n",
    "<br/>\n",
    "We use the elbow method to optimize the number of components (K) that collectively explain at least 70% of the variance in the data. To determine the appropriate number of components, we calculate the variance of each principal component and cumulatively sum the variances until the total variance reaches 0.7 or higher. This process helps us strike a balance between reducing the dimensionality of the data while retaining a substantial amount of the original information. Through PCA we were able to reduce the 14 input variables into 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c890897f-6c9c-4d12-bc27-3023d78a5b86",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 7. Algorithms\n",
    "Various models were trained and hypertuned on the 3 and 12 months datasets in order to obtain the best model. A baseline model was built using Logistic Regression and trained on the 3 month dataset to be used as a reference for the hypertuned models. After a baseline was created, 4 more complex models were trained and hypertuned on the 12 month dataset. The algorithms that were hypertuned were Logistic Regression, Random Forest, Extreme Gradient Boosting, and Multilayer Perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "330f1313-d282-421d-af7a-342a27913ada",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 7.1 Logistic Regression (Baseline)\n",
    "The logistic regression model is a supervised machine learning algorithm that is used for classification and predictive analytics for binary dependent variables. In the context of this study, the dependent variable is **flight_delay**, where a flight delay is considered to be any flight with a departure delay time equal to or greater than 15 minutes, and the model is trying to predict whether a flight will be delayed (**flight_delay = 1**) or not (**flight_delay = 0**). Due to the simplicity of this model, a unhypertuned logistic regression model was created as a baseline model. This model itself does not have a lot of predictive power; however, it provides a reference that can be compared with the more complex models that are created below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9add66dc-e56f-4158-a481-f880b9a07dd2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 7.2 Logistic Regression (Hypertuned)\n",
    "To build on the logistic regression, various parameters (hyperparameters) were added to the model and tuned in order to improve the test metrics. The hyperparameters used for tuning in this model are `regParam`, `maxIter`, and `elasticNetParam`. \n",
    "\n",
    "* `regParam` is used to control the 'strength' of L1 and L2 regularization to prevent overfitting\n",
    "* `maxIter` controls the number of iterations the model goes through during the training process. \n",
    "* `elasticNetParam` is used to select between Ridge (L2) and Lasso (L1) regularization. It has a range between 0 and 1, where 0 corresponds to L2 and 1 corresponds to L1. The hyperparameter values tested and the best value (decided using F1 score) are shown in the table below.\n",
    "\n",
    "Both the tested and best values of the hyperparameters are listed in the table below:\n",
    "\n",
    "| **Hyperparameter** | **Hyperparamters Tested** | **Best Hyperparameter Value** | \n",
    "|:-------|:--------:|:--------:\n",
    "| regParam | [0.005, 0.001, 0.01, 0.1] | 0.43 | \n",
    "| maxIter | [50, 75, 100] | 130 |\n",
    "| elasticNetParam | [0.0, 0.5, 1.0] | 0.0 |\n",
    "\n",
    "**Table 4**: Logistic Regression Hyperparameters\n",
    "<br/><br/>\n",
    "\n",
    "![LR 12m](files/tables/Screenshot_2023_08_09_at_9_13_45_PM.png)\n",
    "**Figure 9**: The ML-Flow experiment log for the Logistic Regression, displaying the wall time, parameters, and evaluation metrics for the 12 months dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f144624-bfeb-4d3c-ae78-f7d73a9e836a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 7.3 Random Forest (RF)\n",
    "The RF model is a supervised machine learning algorithm that is used for classification and regression tasks. The RF algorithm will construct a decision tree for each training set. After the trees are constructed, it will perform 'voting' by taking the average of each decision tree and the decision tree with the highest average is selected as the final model.\n",
    "\n",
    "A tuned RF model was created using the following hyperparameters: `regParam`, `maxIter`, and `elasticNetParam`. \n",
    "\n",
    "* `regParam` is used to control the 'strength' of L1 and L2 regularization to prevent overfitting\n",
    "* `maxIter` controls the number of iterations the model goes through during the training process. \n",
    "* `elasticNetParam` is used to select between Ridge (L2) and Lasso (L1) regularization. It has a range between 0 and 1, where 0 corresponds to L2 and 1 corresponds to L1. The hyperparameter values tested and the best value (decided using F1 score) are shown in the table below.\n",
    "\n",
    "Both the tested and best values of the hyperparameters are listed in the table below:\n",
    "\n",
    "| **Hyperparameter** | **Hyperparamters Tested** | **Best Hyperparameter Value** | \n",
    "|:-------|:--------:|:--------:\n",
    "| regParam | [0.005, 0.001, 0.01, 0.1] | 0.001 | \n",
    "| maxIter | [50, 75, 100] | 50 |\n",
    "| elasticNetParam | [0.0, 0.5, 1.0] | 0.0 |\n",
    "\n",
    "**Table 5**: Random Forest Hyperparameters <br/><br/>\n",
    "\n",
    "![RF 12m](files/tables/Screenshot_2023_08_09_at_8_55_50_PM.png)\n",
    "**Figure 10**: The ML-Flow experiment log for the Random Forest, displaying the wall time, parameters, and evaluation metrics for the 12 months dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be5b77cc-3564-4269-ba20-30e701dfda26",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 7.4 Extreme Gradient Boosting (XGBoost)\n",
    "The XGBoost model is an ensemble machine learning algorithm that is used for classification and regression tasks. This algorithm is an implementation of Gradient Boosting and will construct multiple decision trees, where each tree is trained on a subset of the data and outputs a prediction. The predictions of the trees are then combined at the end to form the final prediction.\n",
    "\n",
    "A tuned XGBoost model was created using the following hyperparameters: `regParam`, `maxIter`, and `elasticNetParam`. \n",
    "* `num_workers` is used to control how many parallel workers are used when training the model\n",
    "* `n_estimators` controls the number of iterations the model goes through during the training process. \n",
    "* `max_bin` controls the number of bins\n",
    "* `max_depth` controls the depth of the tree and increasing this value makes the model more complex, but can lead to overfitting if set too high.\n",
    "* `learning_rate` reprsents the shrinkage at each step.\n",
    "* `max_leaves` represents the maximum number nodes to be added.\n",
    "* `gamma` represents the minimum loss reduction required to make a further partition on a leaf node of a the tree.\n",
    "* `scale_pos_weight` controls the balance of positive and negative weights, helpful for unbalanced classes.\n",
    "\n",
    "Both the tested and best values of the hyperparameters are listed in the table below:\n",
    "\n",
    "| **Hyperparameter** | **Hyperparamters Tested** | **Best Hyperparameter Value(s)** | \n",
    "|:-------|:--------:|:--------:\n",
    "| num_workers | [1 -> 6] | 4 (+/- 1) | \n",
    "| n_estimators | [50 -> 200] | 90 (+/- 10) |\n",
    "| max_bin | [10 -> 40] | 24 (+/ 3) |\n",
    "| max_depth| [4 -> 32] | 10 (+/- 2) |\n",
    "| learning_rate| [0 -> 1] | 0.6 (+/- 0.1) |\n",
    "| max_leaves| [4 -> 32] | 8 (+/- 1) |\n",
    "| gamma| [0 -> 100] | 10 (+/- 4) |\n",
    "| scale_pos_weight| [.1 -> .8] | 1.25 (+/- 0.05) |\n",
    "\n",
    "**Table 6**: XGBoost Hyperparameters <br/><br/>\n",
    "\n",
    "![XGBoost 12m](files/tables/image__1_.png)<br/>\n",
    "**Figure 11**: The ML-Flow experiment log for the XGBoost, displaying the wall time, parameters, and evaluation metrics for the 12 months dataset. \n",
    "<br/><br/>\n",
    "![XGBoost 60m](files/tables/image__2_.png)<br/>\n",
    "**Figure 12**: The ML-Flow experiment log for the XGBoost, displaying the wall time, parameters, and evaluation metrics for the 60 months dataset. \n",
    "<br/><br/>\n",
    "![XGBoost 60m](files/tables/image__6_.png)<br/>\n",
    "**Figure 13**: The ML-Flow experiment log for the XGBoost using time series cross validation method. The table displays the wall time, parameters, and evaluation metrics for the 60 months dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "deffb9aa-f308-48a7-9893-09068ab7e5b0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 7.5 Multilayer Perceptron (MLP)\n",
    "The MLP model is an feed forward neural network algorithm that maps input data to the appropriate output. The neural network can contain multiple hidden intermediate layers to work with more complex classification problems (_problems that are not linearly separable_). \n",
    "\n",
    "A tuned XGBoost model was created using the following hyperparameters: `regParam`, `maxIter`, and `elasticNetParam`. \n",
    "\n",
    "* `maxIter` controls the number of iterations the model goes through during the training process. \n",
    "* `layers` controls the number of layers and the size of each layer. The first value represents the input layer, the last value represents the output layer, and the values in between are all hidden layers. \n",
    "  * **[37, 4, 2]**: MLP - 37 - 4 Relu - 2 Softmax\n",
    "  * **[37, 4, 2, 2]**: MLP - 37 - 4 Relu - 2 Relu- 2 Softmax\n",
    "  * **[37, 32, 16, 2]**: MLP - 37 - 32 Relu - 16 Relu- 2 Softmax\n",
    "  * **[37, 20, 2, 1, 2]**: MLP - 37 - 20 Relu - 2 - Relu - 1 Relu - 2 Softmax\n",
    "* `stepSize` (or _learning rate_) controls the amount that the weights are updated during training and has a range between 0 and 1. \n",
    "* `solver` is used to select between 'gd' (or _Gradient Descent_) and 'l-bfgs' (or _Limited Memory Broyden-Fletcher-Goldfarb-Shanno_), which are optimization algorithms that attempt to improve loss.\n",
    "* `blockSize` is for stacking input data in matrices. Data is stacked within partitions and if block size is more than remaining data in a partition then it is adjusted to the size of this data.\n",
    "\n",
    "Both the tested and best values of the hyperparameters are listed in the table below:\n",
    "\n",
    "| **Hyperparameter** | **Hyperparamters Tested** | **Best Hyperparameter Value** | \n",
    "|:-------|:--------:|:--------:\n",
    "| maxIter | (50, 200, step=25) | 175 | \n",
    "| layers | [[37, 4, 2], [37, 4, 2, 2], [37, 32, 16, 2], [37, 20, 2, 1, 2]] | [37, 32, 16, 2] |\n",
    "| stepSize | (0.1, 1, step=0.1) | 0.8 |\n",
    "| solver | ['gd', 'l-bfgs'] | l-bfgs |\n",
    "| blockSize | (16, 128, step=16) | 96 |\n",
    "\n",
    "**Table 7**: Multilayer Perceptron Hyperparameters. <br/><br/>\n",
    "\n",
    "![NN 12m](files/tables/Screenshot_2023_08_09_at_9_08_53_PM.png)\n",
    "**Figure 14**: The ML-Flow experiment log for the MLP, displaying the wall time, parameters, and evaluation metrics for the 12 months dataset. \n",
    "<br/><br/>\n",
    "![NN 60m](files/tables/Screenshot_2023_08_09_at_9_10_48_PM.png)\n",
    "**Figure 15**: The ML-Flow experiment log for the MLP, displaying the wall time, parameters, and evaluation metrics for the 60 months dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e127cba2-531c-474e-a0a0-d516a9da2ee1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 8. Conclusions and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02719ca7-f03f-48ba-8c41-e52ab2ace5f0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 8.1 Evaluation Metrics\n",
    "\n",
    "The initial metrics used to evaluate the models were **accuracy**, **recall**, **precision**, and **F1 score**. However, of the 6 metrics listed, **F1 score** was the metric that was ultimately used to determine the best models. **Accuracy** was not used due to the fact that the dataset had an imbalanced distribution of classes. **Precision** was a strong contender because it punishes the model for predicting false positives (which in the context of the issue would be stating that a flight is delayed when in reality it is on time); however, this metric does not take failing to predict a flight delay into account. Alternatively, **recall** handles the issue of failing to predict delayed flights; yet, it does not punish false positives. Ultimately, we decided to prioritize F1 score because it not only combines both precision and recall, but also has the added benefit of being compatible with Grid Search tuning. With addition time, we would consider using AUC-ROC and AUC-PR and F2 score, this is furher discussed in the conclusion gap analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a8ac40a-1393-4f52-b7b1-c99a74eb5d96",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 8.1.1 Accuracy\n",
    "\n",
    "$$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "**Formula 1:** Accuracy Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e95aa4d9-af16-4c1c-9c9e-255d616e2636",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 8.1.2 Recall\n",
    "\n",
    "$$Recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "**Formula 2:** Recall Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86358089-d8e3-4277-abc9-c300d62ce620",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 8.1.3 Precision\n",
    "\n",
    "$$Precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "**Formula 3:** Precision Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbf4c7b3-cb3f-44f4-b0b3-16ec9a8fb5eb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 8.1.4 F1 Score\n",
    "\n",
    "$$F1 = \\frac{2 * (Precision * Recall)}{Precision + Recall}$$\n",
    "\n",
    "**Formula 4:** F1 Score Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fafa6d3a-327f-4a76-a690-cf011b7c75e8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 8.2 Model Summary and Results\n",
    "The following table summarizes all each model's performance on the 3, 12, and 60 month datasets. The models were chosen based on the highest F1 score and the other metrics associated with that model are documented as well. Ultimately, XGBoost was determined to be the best model (_based on F1 score and runtime_) and was run against the heldout set to obtain the final F1 score of **77.2%**.\n",
    "\n",
    "_For more in-depth information about model runtime, experimentation, and selection, refer to the subsections_ \n",
    "\n",
    "![eval metric](files/tables/image__8_.png)<br/>\n",
    "**Table 8**: This table showcases the model's performance across the 3, 12, and 60-month datasets, assessed using various evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3884415-73d6-4fd5-bbcf-893c6f84eafa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 8.2.1 3 Month Model Summary\n",
    "\n",
    "The evaluation metrics for the 4 models on the 3 month dataset are documented in the table below. For these models, the training data was based on the first two months and the validation set was based on the last month. From the results below, XGBoost outperformed the other 3 models based on its F1 score and runtime. Although all 4 models were eventually able to find similar scores, ~75%, the XGBoost model took less training attempts to achieve a high F1 score relative to other models.\n",
    "\n",
    "| **Hyperparameter** | **F1 Score** | Model Runs Attempts | Approx. Runtime\n",
    "|:-------|:--------:|:--------:|:--------:|\n",
    "| Logistic Regression (LR) | 75.7% |135|~5 minutes|\n",
    "| Random Forest (RF) | 75.71%|46|~9 minutes|\n",
    "| XGBoost (XGB) | 75.8%|56|~4 minutes|\n",
    "| Multilayer Perception| 75.6% |76 |~7 minutes|\n",
    "\n",
    "**Table 9**: This table showcases each model's best F1 Score for the 3 month dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b2ec7bc-e85d-47bd-a37c-0a3e665b2893",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 8.2.2 12 Month Model Summary\n",
    "The evaluation metrics for the 4 models on the 12 month dataset are documented in the table below. For these models, the training data was based on the first 8 months and the validation set was based on the remaining 4 months. While training against the 1 year data, it was necessary to compare training and validation F1 scores to check for overfitting against the training set. Interestingly, the training F1 score performed worse than the validation F1 scores; therefore, it was safe to assume that the models were not overfitting against the training data. From the results below, XGBoost still outperformed the other 3 models based on its F1 score. Furthermore, the models were able to achieve a higher F1 score using similar hyperparameters on a larger dataset. As mentioned in the previous section, XGBoost took less training attempts to achieve a high F1 score relative to other models. During this stage of model training, the recall was very high for many of these models (95%>); however, precision was often much lower (75~85%). This could be indicative of a class imbalance, which may contribute to the low precision score. This issue was addressed by applying the ```scale_pos_weight``` hyperparameter to XGBoost, which resulted in a greater balance between precision and recall.\n",
    "\n",
    "| **Hyperparameter** |**F1 Score** Train | **F1 Score** Validation| Model Runs Attempts | Approx. Runtime\n",
    "|:-------|:--------:|:--------:|:--------:|:--------:|\n",
    "| Logistic Regression (LR) |71.6%| 78.0% |40|~5 minutes|\n",
    "| Random Forest (RF) |77.9| 79.5%|20|10~17 minutes|\n",
    "| XGBoost (XGB) |75.2%| 80.0%|85|7~8 minutes|\n",
    "| Multilayer Perception|73.9| 79.7% |5|~15 minutes|\n",
    "\n",
    "**Table 10**: This table showcases each model's best F1 Score for the 12 month dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d24a798d-8429-46b5-a80e-9e4975626aa0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 8.2.3 60 Month Model Summary\n",
    "The evaluation metrics for the XGBoost and MLP model on the 60 month dataset are documented in the table below.  For these models, the training data was based on the first 3 years, the validation was based on the 4th year, and the held testing out set was based on the 5th year. Ultimately, XGBoost was determined to be the best performing model due to its higher F1 score and it had a faster runtime than the MLP model. For that reason, XGBoost was also hypertuned against the 3 years of training data. Initially, the F1 score was stuck around 75.6; however, through the addition of the ```scale_pos_weight``` hyperparameter, which would correct for imbalanced data, the model was able to achieve a F1 score of 78.3%. Once the final set of hyperparamters were generated, the model was run using time series cross validation. It was important to verify how the model would perform using time series cross validation because the previous model was developed using pre-scaled training data. Against the time series cross validation, the model achieved an F1 score of 73.3%, which was concerning because there was a noticeable decrease in F1 score. However, when running the model on the held out test set, the model achieved an F1 score of 77.2%. This was satisfactory because even with the intentional pre-scaling, the model was still effective on the held out test set relative to the validation set.  \n",
    "\n",
    "| **Hyperparameter** |**F1 Score** Train |  **F1 Score** | Model Runs Attempts | Approx. Runtime\n",
    "|:-------|:--------:|:--------:|:--------:|:--------:|\n",
    "| XGBoost (XGB) |78.1% |77.6%|50|12~18 minutes|\n",
    "| XGBoost (XGB) - Time Series Cross Val | 77.6% | 73.3%|3|~15 minutes|\n",
    "| XGBoost (XGB) - Holdout |77.9%| 77.2%|1|12~18 minutes|\n",
    "| Multilayer Perception| 75.1% | 74.9% |3|20~40 minutes|\n",
    "\n",
    "\n",
    "**Table 11**: This table showcases each model's best F1 Score for the 60 month dataset, time series cross validation is based on a mean derived from each fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10affa0e-4cb7-4627-9725-fe8df919f301",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 8.3 Conclusions\n",
    "\n",
    "In this study, we aimed to improve United Airlines' flight delay detection using machine learning. Our hypothesis was that customized ML pipelines could accurately predict delays, enhancing operational efficiency and passenger satisfaction. Our focus was on data preprocessing, feature engineering, and hyperparameter tuning, leading to the creation of four models of which an optimized XGBoost model demonstrated the ability to predict true positives the best.\n",
    "\n",
    "The final XGBoost F1 score was 77.2% which outperformed the F1 scores posted by other groups for the testing set by a slight margin. Our 69.2% AUC-ROC and 33.6% AUC-PR underperformed relative to other teams, which are metrics that United should consider focusing on for future improvements. The primary improvement that other teams with better AUC-ROC & AUC-PR scores made was better handling of class balance. Although we were able to somewhat handle imbalancing through hypertuning, applying resampling at the beginning of the pipeline could have benefitted all of our models. For example, SMOTE could be used to generate additional data to balance classes.\n",
    "\n",
    "Looking forward, future iterations can explore the dataset joins with a different weather dataset, additional graph based features, as well as more experiments and hypertuning iterations. We believe our work paves the way for data-driven decision-making in air travel, aligning with United Airlines' commitment to excellence and innovation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68b0963f-23f6-43e4-8272-8978d1932a48",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 9. Future Work\n",
    "\n",
    "This study occurred over the course of a 4-week period; therefore, there were many avenues that were unable to be explored due to time and resource constraints. Some future work that could be done to improve upon this study are detailed below:\n",
    "\n",
    "* In the context of this study, a delay is defined as any flight that has a departure time later than 15 minutes; however, this definition conflicted with the weather data that provided information that was 2 hours off from the departure time. If given more time, the joining of the dataset would be modified, where a different weather dataset.\n",
    "\n",
    "* When creating features, there was an attempt to create a feature to represent Airport Betweenness Centrality. This would be a graph based feature that would identify critical hubs connecting other airports. However, due to limitations of the cluster resources, this feature was not able to be added successfully due to the cluster constantly crashing when running the page-rank code. \n",
    "\n",
    "* Integrate supplementary features from weather, flights, and station data into the Principal Component Analysis (PCA) process, regardless of their apparent significance, in order to extract all possible information.\n",
    "\n",
    "* In the future, more experiments and hypertuning iterations would be done for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "627f5a64-96cd-418f-a3ae-5b30b796b569",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##10. Relevant Notebooks\n",
    "\n",
    "**EDA**: https://adb-4248444930383559.19.azuredatabricks.net/?o=4248444930383559#notebook/3984215836264129/command/3984215836265270\n",
    "<br>\n",
    "**Feature Engineering**: https://adb-4248444930383559.19.azuredatabricks.net/?o=4248444930383559#notebook/3984215836265391/command/3984215836274414\n",
    "<br>\n",
    "**Feature Engineering (60 MONTHS KFold)**: https://adb-4248444930383559.19.azuredatabricks.net/?o=4248444930383559#notebook/3984215836275988/command/3984215836275989\n",
    "<br>\n",
    "<br>\n",
    "**Logistic Regression (3 MONTHS)**: https://adb-4248444930383559.19.azuredatabricks.net/?o=4248444930383559#notebook/3984215836270534/command/3984215836270540\n",
    "<br>\n",
    "**Logistic Regression (12 MONTHS)**: https://adb-4248444930383559.19.azuredatabricks.net/?o=4248444930383559#notebook/3984215836277745\n",
    "<br>\n",
    "<br>\n",
    "**Random Forest (3 MONTHS)**: https://adb-4248444930383559.19.azuredatabricks.net/?o=4248444930383559#notebook/3984215836275167/command/3984215836275233\n",
    "<br>\n",
    "**Random Forest (12 MONTHS)**: https://adb-4248444930383559.19.azuredatabricks.net/?o=4248444930383559#notebook/3984215836275897/command/3984215836275898\n",
    "<br>\n",
    "<br>\n",
    "**XG Boost (3 MONTHS)**: https://adb-4248444930383559.19.azuredatabricks.net/?o=4248444930383559#notebook/3984215836275056/command/3984215836275057\n",
    "<br>\n",
    "**XG Boost (12 MONTHS)**: https://adb-4248444930383559.19.azuredatabricks.net/?o=4248444930383559#notebook/3984215836275668/command/3984215836275669\n",
    "<br>\n",
    "**XG Boost (60 MONTHS)**: https://adb-4248444930383559.19.azuredatabricks.net/?o=4248444930383559#notebook/3984215836275734/command/3984215836275735\n",
    "<br>\n",
    "<br>\n",
    "**Multilayer Perceptron (3 MONTHS)**: https://adb-4248444930383559.19.azuredatabricks.net/?o=4248444930383559#notebook/3984215836275130/command/3984215836275163\n",
    "<br>\n",
    "**Multilayer Perceptron (12 MONTHS)**: https://adb-4248444930383559.19.azuredatabricks.net/?o=4248444930383559#notebook/3984215836277845\n",
    "<br>\n",
    "**Multilayer Perceptron (60 MONTHS)**: https://adb-4248444930383559.19.azuredatabricks.net/?o=4248444930383559#notebook/3984215836277706\n",
    "<br>\n",
    "<br>\n",
    "**Phase 1**: https://adb-4248444930383559.19.azuredatabricks.net/?o=4248444930383559#notebook/258482184172158/command/258482184172159\n",
    "<br>\n",
    "**Phase 2**: https://adb-4248444930383559.19.azuredatabricks.net/?o=4248444930383559#notebook/3631218846932078/command/3631218846932079\n",
    "<br>\n",
    "**Phase 3**: https://adb-4248444930383559.19.azuredatabricks.net/?o=4248444930383559#notebook/1684466716985002/command/1684466716985003\n",
    "<br>\n",
    "**Final Research Report (THIS NOTEBOOK)**: https://adb-4248444930383559.19.azuredatabricks.net/?o=4248444930383559#notebook/3984215836274514/command/3984215836274585"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52d723f8-187d-4f41-9286-56104e0ee6bf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Works Cited\n",
    "\n",
    "* **Data Leakage Article**: Maddali, Suhas. “What Is Data Leakage, and How Can It Be Avoided in Machine Learning?” Medium, 14 June 2022, towardsdatascience.com/what-is-data-leakage-and-how-can-it-be-avoided-in-machine-learning-eb435a27c3e3. Accessed 7 Aug. 2023.\n",
    "* **Time Series CV Figure**: Shrivastava, Soumya. “Cross Validation in Time Series.” Medium, 17 Jan. 2020, medium.com/@soumyachess1496/cross-validation-in-time-series-566ae4981ce4. \n",
    "* **MLP Documentation**: “MultilayerPerceptronClassifier — PySpark 3.3.1 Documentation.” Spark.apache.org, spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.MultilayerPerceptronClassifier.html.\n",
    "* **United Airline Information**: “United Airlines Fleet & Aircraft Information | United Airlines.” United.com, 2018, www.united.com/ual/en/us/fly/travel/inflight/united-airlines-fleet.html.\n",
    "* **Southwest Airline Information**: “Southwest Corporate Fact Sheet.” Southwest Airlines Newsroom, https://swamedia.com/pages/corporate-fact-sheet#fleet.\n",
    "* **Hawaiian Airline Information**: “Our Fleet.” Hawaiian Airlines, www.hawaiianairlines.com/our-services/at-the-airport/our-fleet.\n",
    "* **American Airline Information**: “Planes − Travel Information − American Airlines.” Www.aa.com, www.aa.com/i18n/travel-info/experience/planes/planes.jsp.\n",
    "* **Delta Airline Information**: “Delta Aircraft Seat Maps, Specs & Amenities.” Www.delta.com, www.delta.com/us/en/aircraft/overview."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12aa2eef-7bcf-4462-9605-b571d124209e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "789d32ef-9559-493a-ba55-99559d34fb24",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## A.1 Original Dataset Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40173159-c4d6-4275-ac25-ece5fe1178aa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### A.1.1 Flight Full Data Summary\n",
    "| Feature Name            | Data Type   |   Null Count |   Non Null Count |\n",
    "|:------------------------|:------------|-------------:|-----------------:|\n",
    "| QUARTER                 | int         |            0 |          2806942 |\n",
    "| MONTH                   | int         |            0 |          2806942 |\n",
    "| DAY_OF_MONTH            | int         |            0 |          2806942 |\n",
    "| DAY_OF_WEEK             | int         |            0 |          2806942 |\n",
    "| FL_DATE                 | string      |            0 |          2806942 |\n",
    "| OP_UNIQUE_CARRIER       | string      |            0 |          2806942 |\n",
    "| OP_CARRIER_AIRLINE_ID   | int         |            0 |          2806942 |\n",
    "| OP_CARRIER              | string      |            0 |          2806942 |\n",
    "| TAIL_NUM                | string      |        16380 |          2790562 |\n",
    "| OP_CARRIER_FL_NUM       | int         |            0 |          2806942 |\n",
    "| ORIGIN_AIRPORT_ID       | int         |            0 |          2806942 |\n",
    "| ORIGIN_AIRPORT_SEQ_ID   | int         |            0 |          2806942 |\n",
    "| ORIGIN_CITY_MARKET_ID   | int         |            0 |          2806942 |\n",
    "| ORIGIN                  | string      |            0 |          2806942 |\n",
    "| ORIGIN_CITY_NAME        | string      |            0 |          2806942 |\n",
    "| ORIGIN_STATE_ABR        | string      |            0 |          2806942 |\n",
    "| ORIGIN_STATE_FIPS       | int         |            0 |          2806942 |\n",
    "| ORIGIN_STATE_NM         | string      |            0 |          2806942 |\n",
    "| ORIGIN_WAC              | int         |            0 |          2806942 |\n",
    "| DEST_AIRPORT_ID         | int         |            0 |          2806942 |\n",
    "| DEST_AIRPORT_SEQ_ID     | int         |            0 |          2806942 |\n",
    "| DEST_CITY_MARKET_ID     | int         |            0 |          2806942 |\n",
    "| DEST                    | string      |            0 |          2806942 |\n",
    "| DEST_CITY_NAME          | string      |            0 |          2806942 |\n",
    "| DEST_STATE_ABR          | string      |            0 |          2806942 |\n",
    "| DEST_STATE_FIPS         | int         |            0 |          2806942 |\n",
    "| DEST_STATE_NM           | string      |            0 |          2806942 |\n",
    "| DEST_WAC                | int         |            0 |          2806942 |\n",
    "| CRS_DEP_TIME            | int         |            0 |          2806942 |\n",
    "| DEP_TIME                | int         |        84710 |          2722232 |\n",
    "| DEP_DELAY               | double      |        84710 |          2722232 |\n",
    "| DEP_DELAY_NEW           | double      |        84710 |          2722232 |\n",
    "| DEP_DEL15               | double      |        84710 |          2722232 |\n",
    "| DEP_DELAY_GROUP         | int         |        84710 |          2722232 |\n",
    "| DEP_TIME_BLK            | string      |            0 |          2806942 |\n",
    "| TAXI_OUT                | double      |        86342 |          2720600 |\n",
    "| WHEELS_OFF              | int         |        86342 |          2720600 |\n",
    "| WHEELS_ON               | int         |        88736 |          2718206 |\n",
    "| TAXI_IN                 | double      |        88736 |          2718206 |\n",
    "| CRS_ARR_TIME            | int         |            0 |          2806942 |\n",
    "| ARR_TIME                | int         |        88736 |          2718206 |\n",
    "| ARR_DELAY               | double      |        93314 |          2713628 |\n",
    "| ARR_DELAY_NEW           | double      |        93314 |          2713628 |\n",
    "| ARR_DEL15               | double      |        93314 |          2713628 |\n",
    "| ARR_DELAY_GROUP         | int         |        93314 |          2713628 |\n",
    "| ARR_TIME_BLK            | string      |            0 |          2806942 |\n",
    "| CANCELLED               | double      |            0 |          2806942 |\n",
    "| CANCELLATION_CODE       | string      |      2719940 |            87002 |\n",
    "| DIVERTED                | double      |            0 |          2806942 |\n",
    "| CRS_ELAPSED_TIME        | double      |            4 |          2806938 |\n",
    "| ACTUAL_ELAPSED_TIME     | double      |        93314 |          2713628 |\n",
    "| AIR_TIME                | double      |        93314 |          2713628 |\n",
    "| FLIGHTS                 | double      |            0 |          2806942 |\n",
    "| DISTANCE                | double      |            0 |          2806942 |\n",
    "| DISTANCE_GROUP          | int         |            0 |          2806942 |\n",
    "| CARRIER_DELAY           | double      |      2233778 |           573164 |\n",
    "| WEATHER_DELAY           | double      |      2233778 |           573164 |\n",
    "| NAS_DELAY               | double      |      2233778 |           573164 |\n",
    "| SECURITY_DELAY          | double      |      2233778 |           573164 |\n",
    "| LATE_AIRCRAFT_DELAY     | double      |      2233778 |           573164 |\n",
    "| FIRST_DEP_TIME          | int         |      2788958 |            17984 |\n",
    "| TOTAL_ADD_GTIME         | double      |      2788958 |            17984 |\n",
    "| LONGEST_ADD_GTIME       | double      |      2788958 |            17984 |\n",
    "| DIV_AIRPORT_LANDINGS    | int         |            0 |          2806942 |\n",
    "| DIV_REACHED_DEST        | double      |      2800630 |             6312 |\n",
    "| DIV_ACTUAL_ELAPSED_TIME | double      |      2802364 |             4578 |\n",
    "| DIV_ARR_DELAY           | double      |      2802364 |             4578 |\n",
    "| DIV_DISTANCE            | double      |      2800630 |             6312 |\n",
    "| DIV1_AIRPORT            | string      |      2799970 |             6972 |\n",
    "| DIV1_AIRPORT_ID         | int         |      2799970 |             6972 |\n",
    "| DIV1_AIRPORT_SEQ_ID     | int         |      2799970 |             6972 |\n",
    "| DIV1_WHEELS_ON          | int         |      2799970 |             6972 |\n",
    "| DIV1_TOTAL_GTIME        | double      |      2799970 |             6972 |\n",
    "| DIV1_LONGEST_GTIME      | double      |      2799970 |             6972 |\n",
    "| DIV1_WHEELS_OFF         | int         |      2802266 |             4676 |\n",
    "| DIV1_TAIL_NUM           | string      |      2802266 |             4676 |\n",
    "| DIV2_AIRPORT            | string      |      2806822 |              120 |\n",
    "| DIV2_AIRPORT_ID         | string      |      2806822 |              120 |\n",
    "| DIV2_AIRPORT_SEQ_ID     | string      |      2806822 |              120 |\n",
    "| DIV2_WHEELS_ON          | string      |      2806822 |              120 |\n",
    "| DIV2_TOTAL_GTIME        | string      |      2806822 |              120 |\n",
    "| DIV2_LONGEST_GTIME      | string      |      2806822 |              120 |\n",
    "| DIV2_WHEELS_OFF         | string      |      2806916 |               26 |\n",
    "| DIV2_TAIL_NUM           | string      |      2806916 |               26 |\n",
    "| DIV3_AIRPORT            | string      |      2806938 |                4 |\n",
    "| DIV3_AIRPORT_ID         | string      |      2806938 |                4 |\n",
    "| DIV3_AIRPORT_SEQ_ID     | string      |      2806938 |                4 |\n",
    "| DIV3_WHEELS_ON          | string      |      2806938 |                4 |\n",
    "| DIV3_TOTAL_GTIME        | string      |      2806938 |                4 |\n",
    "| DIV3_LONGEST_GTIME      | string      |      2806938 |                4 |\n",
    "| DIV3_WHEELS_OFF         | string      |      2806942 |                0 |\n",
    "| DIV3_TAIL_NUM           | string      |      2806942 |                0 |\n",
    "| DIV4_AIRPORT            | string      |      2806942 |                0 |\n",
    "| DIV4_AIRPORT_ID         | string      |      2806942 |                0 |\n",
    "| DIV4_AIRPORT_SEQ_ID     | string      |      2806942 |                0 |\n",
    "| DIV4_WHEELS_ON          | string      |      2806942 |                0 |\n",
    "| DIV4_TOTAL_GTIME        | string      |      2806942 |                0 |\n",
    "| DIV4_LONGEST_GTIME      | string      |      2806942 |                0 |\n",
    "| DIV4_WHEELS_OFF         | string      |      2806942 |                0 |\n",
    "| DIV4_TAIL_NUM           | string      |      2806942 |                0 |\n",
    "| DIV5_AIRPORT            | string      |      2806942 |                0 |\n",
    "| DIV5_AIRPORT_ID         | string      |      2806942 |                0 |\n",
    "| DIV5_AIRPORT_SEQ_ID     | string      |      2806942 |                0 |\n",
    "| DIV5_WHEELS_ON          | string      |      2806942 |                0 |\n",
    "| DIV5_TOTAL_GTIME        | string      |      2806942 |                0 |\n",
    "| DIV5_LONGEST_GTIME      | string      |      2806942 |                0 |\n",
    "| DIV5_WHEELS_OFF         | string      |      2806942 |                0 |\n",
    "| DIV5_TAIL_NUM           | string      |      2806942 |                0 |\n",
    "| YEAR                    | int         |            0 |          2806942 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "250898bf-3e57-4d5c-adbd-3f7bfc619c85",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### A.1.2 Weather Full Data Summary\n",
    "| Feature Name                                 | Data Type   |   Null Count |   Non Null Count |\n",
    "|:---------------------------------------------|:------------|-------------:|-----------------:|\n",
    "| STATION                                      | string      |            0 |         30528602 |\n",
    "| DATE                                         | string      |            0 |         30528602 |\n",
    "| LATITUDE                                     | string      |       241154 |         30287448 |\n",
    "| LONGITUDE                                    | string      |       241154 |         30287448 |\n",
    "| ELEVATION                                    | string      |       241154 |         30287448 |\n",
    "| NAME                                         | string      |       241154 |         30287448 |\n",
    "| REPORT_TYPE                                  | string      |            0 |         30528602 |\n",
    "| SOURCE                                       | string      |            0 |         30528602 |\n",
    "| HourlyAltimeterSetting                       | string      |     14077864 |         16450738 |\n",
    "| HourlyDewPointTemperature                    | string      |      5363413 |         25165189 |\n",
    "| HourlyDryBulbTemperature                     | string      |       651063 |         29877539 |\n",
    "| HourlyPrecipitation                          | string      |     26596147 |          3932455 |\n",
    "| HourlyPresentWeatherType                     | string      |     26599574 |          3929028 |\n",
    "| HourlyPressureChange                         | string      |     22102547 |          8426055 |\n",
    "| HourlyPressureTendency                       | string      |     21803877 |          8724725 |\n",
    "| HourlyRelativeHumidity                       | string      |      5371495 |         25157107 |\n",
    "| HourlySkyConditions                          | string      |     14476375 |         16052227 |\n",
    "| HourlySeaLevelPressure                       | string      |     19468244 |         11060358 |\n",
    "| HourlyStationPressure                        | string      |     15025512 |         15503090 |\n",
    "| HourlyVisibility                             | string      |     10576036 |         19952566 |\n",
    "| HourlyWetBulbTemperature                     | string      |     15281390 |         15247212 |\n",
    "| HourlyWindDirection                          | string      |      4351048 |         26177554 |\n",
    "| HourlyWindGustSpeed                          | string      |     28340702 |          2187900 |\n",
    "| HourlyWindSpeed                              | string      |      4044614 |         26483988 |\n",
    "| Sunrise                                      | string      |     30377170 |           151432 |\n",
    "| Sunset                                       | string      |     30377160 |           151442 |\n",
    "| DailyAverageDewPointTemperature              | string      |     30499862 |            28740 |\n",
    "| DailyAverageDryBulbTemperature               | string      |     30423710 |           104892 |\n",
    "| DailyAverageRelativeHumidity                 | string      |     30499631 |            28971 |\n",
    "| DailyAverageSeaLevelPressure                 | string      |     30499896 |            28706 |\n",
    "| DailyAverageStationPressure                  | string      |     30438234 |            90368 |\n",
    "| DailyAverageWetBulbTemperature               | string      |     30499862 |            28740 |\n",
    "| DailyAverageWindSpeed                        | string      |     30437818 |            90784 |\n",
    "| DailyCoolingDegreeDays                       | string      |     30423710 |           104892 |\n",
    "| DailyDepartureFromNormalAverageTemperature   | string      |     30434429 |            94173 |\n",
    "| DailyHeatingDegreeDays                       | string      |     30423710 |           104892 |\n",
    "| DailyMaximumDryBulbTemperature               | string      |     30423681 |           104921 |\n",
    "| DailyMinimumDryBulbTemperature               | string      |     30423689 |           104913 |\n",
    "| DailyPeakWindDirection                       | string      |     30440690 |            87912 |\n",
    "| DailyPeakWindSpeed                           | string      |     30436954 |            91648 |\n",
    "| DailyPrecipitation                           | string      |     30423616 |           104986 |\n",
    "| DailySnowDepth                               | string      |     30490669 |            37933 |\n",
    "| DailySnowfall                                | string      |     30491778 |            36824 |\n",
    "| DailySustainedWindDirection                  | string      |     30437703 |            90899 |\n",
    "| DailySustainedWindSpeed                      | string      |     30436892 |            91710 |\n",
    "| DailyWeather                                 | string      |     30434968 |            93634 |\n",
    "| MonthlyAverageRH                             | string      |     30528602 |                0 |\n",
    "| MonthlyDaysWithGT001Precip                   | string      |     30525362 |             3240 |\n",
    "| MonthlyDaysWithGT010Precip                   | string      |     30525362 |             3240 |\n",
    "| MonthlyDaysWithGT32Temp                      | string      |     30525420 |             3182 |\n",
    "| MonthlyDaysWithGT90Temp                      | string      |     30525423 |             3179 |\n",
    "| MonthlyDaysWithLT0Temp                       | string      |     30525420 |             3182 |\n",
    "| MonthlyDaysWithLT32Temp                      | string      |     30525420 |             3182 |\n",
    "| MonthlyDepartureFromNormalAverageTemperature | string      |     30525496 |             3106 |\n",
    "| MonthlyDepartureFromNormalCoolingDegreeDays  | string      |     30525517 |             3085 |\n",
    "| MonthlyDepartureFromNormalHeatingDegreeDays  | string      |     30525517 |             3085 |\n",
    "| MonthlyDepartureFromNormalMaximumTemperature | string      |     30525496 |             3106 |\n",
    "| MonthlyDepartureFromNormalMinimumTemperature | string      |     30525496 |             3106 |\n",
    "| MonthlyDepartureFromNormalPrecipitation      | string      |     30525827 |             2775 |\n",
    "| MonthlyDewpointTemperature                   | string      |     30528602 |                0 |\n",
    "| MonthlyGreatestPrecip                        | string      |     30525814 |             2788 |\n",
    "| MonthlyGreatestPrecipDate                    | string      |     30525919 |             2683 |\n",
    "| MonthlyGreatestSnowDepth                     | string      |     30527924 |              678 |\n",
    "| MonthlyGreatestSnowDepthDate                 | string      |     30528086 |              516 |\n",
    "| MonthlyGreatestSnowfall                      | string      |     30527915 |              687 |\n",
    "| MonthlyGreatestSnowfallDate                  | string      |     30528017 |              585 |\n",
    "| MonthlyMaxSeaLevelPressureValue              | string      |     30525836 |             2766 |\n",
    "| MonthlyMaxSeaLevelPressureValueDate          | string      |     30525835 |             2767 |\n",
    "| MonthlyMaxSeaLevelPressureValueTime          | string      |     30525835 |             2767 |\n",
    "| MonthlyMaximumTemperature                    | string      |     30525371 |             3231 |\n",
    "| MonthlyMeanTemperature                       | string      |     30525371 |             3231 |\n",
    "| MonthlyMinSeaLevelPressureValue              | string      |     30525839 |             2763 |\n",
    "| MonthlyMinSeaLevelPressureValueDate          | string      |     30525838 |             2764 |\n",
    "| MonthlyMinSeaLevelPressureValueTime          | string      |     30525838 |             2764 |\n",
    "| MonthlyMinimumTemperature                    | string      |     30525371 |             3231 |\n",
    "| MonthlySeaLevelPressure                      | string      |     30525871 |             2731 |\n",
    "| MonthlyStationPressure                       | string      |     30525859 |             2743 |\n",
    "| MonthlyTotalLiquidPrecipitation              | string      |     30525468 |             3134 |\n",
    "| MonthlyTotalSnowfall                         | string      |     30528018 |              584 |\n",
    "| MonthlyWetBulb                               | string      |     30528602 |                0 |\n",
    "| AWND                                         | string      |     30525927 |             2675 |\n",
    "| CDSD                                         | string      |     30525457 |             3145 |\n",
    "| CLDD                                         | string      |     30525433 |             3169 |\n",
    "| DSNW                                         | string      |     30527608 |              994 |\n",
    "| HDSD                                         | string      |     30525645 |             2957 |\n",
    "| HTDD                                         | string      |     30525433 |             3169 |\n",
    "| NormalsCoolingDegreeDay                      | string      |     30525463 |             3139 |\n",
    "| NormalsHeatingDegreeDay                      | string      |     30525463 |             3139 |\n",
    "| ShortDurationEndDate005                      | string      |     30526151 |             2451 |\n",
    "| ShortDurationEndDate010                      | string      |     30526151 |             2451 |\n",
    "| ShortDurationEndDate015                      | string      |     30526151 |             2451 |\n",
    "| ShortDurationEndDate020                      | string      |     30526151 |             2451 |\n",
    "| ShortDurationEndDate030                      | string      |     30526151 |             2451 |\n",
    "| ShortDurationEndDate045                      | string      |     30526151 |             2451 |\n",
    "| ShortDurationEndDate060                      | string      |     30526151 |             2451 |\n",
    "| ShortDurationEndDate080                      | string      |     30526152 |             2450 |\n",
    "| ShortDurationEndDate100                      | string      |     30526152 |             2450 |\n",
    "| ShortDurationEndDate120                      | string      |     30526151 |             2451 |\n",
    "| ShortDurationEndDate150                      | string      |     30526151 |             2451 |\n",
    "| ShortDurationEndDate180                      | string      |     30526157 |             2445 |\n",
    "| ShortDurationPrecipitationValue005           | string      |     30526151 |             2451 |\n",
    "| ShortDurationPrecipitationValue010           | string      |     30526151 |             2451 |\n",
    "| ShortDurationPrecipitationValue015           | string      |     30526151 |             2451 |\n",
    "| ShortDurationPrecipitationValue020           | string      |     30526151 |             2451 |\n",
    "| ShortDurationPrecipitationValue030           | string      |     30526151 |             2451 |\n",
    "| ShortDurationPrecipitationValue045           | string      |     30526151 |             2451 |\n",
    "| ShortDurationPrecipitationValue060           | string      |     30526151 |             2451 |\n",
    "| ShortDurationPrecipitationValue080           | string      |     30526152 |             2450 |\n",
    "| ShortDurationPrecipitationValue100           | string      |     30526152 |             2450 |\n",
    "| ShortDurationPrecipitationValue120           | string      |     30526151 |             2451 |\n",
    "| ShortDurationPrecipitationValue150           | string      |     30526151 |             2451 |\n",
    "| ShortDurationPrecipitationValue180           | string      |     30526157 |             2445 |\n",
    "| REM                                          | string      |      4021654 |         26506948 |\n",
    "| BackupDirection                              | string      |     30010429 |           518173 |\n",
    "| BackupDistance                               | string      |     30007610 |           520992 |\n",
    "| BackupDistanceUnit                           | string      |     30007610 |           520992 |\n",
    "| BackupElements                               | string      |     30001132 |           527470 |\n",
    "| BackupElevation                              | string      |     30126564 |           402038 |\n",
    "| BackupEquipment                              | string      |     30020963 |           507639 |\n",
    "| BackupLatitude                               | string      |     30133883 |           394719 |\n",
    "| BackupLongitude                              | string      |     30133883 |           394719 |\n",
    "| BackupName                                   | string      |     29983831 |           544771 |\n",
    "| WindEquipmentChangeDate                      | string      |     28669085 |          1859517 |\n",
    "| YEAR                                         | int         |            0 |         30528602 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "848285bc-2570-42c4-859a-1b3b1bb29ae8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### A.1.3 Station Full Data Summary\n",
    "| Feature Name         | Data Type   |   Null Count |   Non Null Count |\n",
    "|:---------------------|:------------|-------------:|-----------------:|\n",
    "| usaf                 | string      |            0 |          5004169 |\n",
    "| wban                 | string      |            0 |          5004169 |\n",
    "| station_id           | string      |            0 |          5004169 |\n",
    "| lat                  | double      |            0 |          5004169 |\n",
    "| lon                  | double      |            0 |          5004169 |\n",
    "| neighbor_id          | string      |            0 |          5004169 |\n",
    "| neighbor_name        | string      |            0 |          5004169 |\n",
    "| neighbor_state       | string      |            0 |          5004169 |\n",
    "| neighbor_call        | string      |            0 |          5004169 |\n",
    "| neighbor_lat         | double      |            0 |          5004169 |\n",
    "| neighbor_lon         | double      |            0 |          5004169 |\n",
    "| distance_to_neighbor | double      |            0 |          5004169 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e0cf6b1-2976-45ee-9392-7dffa01d9188",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## A.2 3 Month Dataset EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f7f6842-9df8-413b-b782-fb799e343ab0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### A.2.1 Flights VS Delay Flights by Day of Week\n",
    "![DOW_delay_3m](files/tables/Delay_Flight_DOW.png) <br/>\n",
    "**Figure 16**: A stacked bar plot of all flights vs delay flights by day of week for 3 months dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea090395-c659-403b-a466-487b9c2dc02d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### A.2.2 Flights VS Delay Flights by Airline\n",
    "![DOW_delay_3m](files/tables/Delay_flight_AirLine_3m.png) <br/>\n",
    "**Figure 17**: A stacked bar plot of all flights vs delay flights by airline for 3 months dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d5e3180-b4c5-40ec-8371-ac033a5c8f6f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## A.3 12 Month Dataset EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc25f196-92f1-4a53-9c62-34cafd3e3658",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### A.3.1 All Flights VS Delay Flights by Day of the Week\n",
    "![DOW_delay_3m](files/tables/Delay_Flight_DOW_12m.png) <br/>\n",
    "**Figure 18**: A stacked bar plot of all flights vs delay flights by day of week for 12 months dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5dafb5ac-7333-43dd-8001-a4c23066c0ae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### A.3.2 All Flights VS Delay Flights by Airline\n",
    "![DOW_delay_3m](files/tables/Delay_flight_AirLine_12m.png) <br/>\n",
    "**Figure 19**: A stacked bar plot of all flights vs delay flights by airline for 12 months dataset."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "FP_Section2_Group4_Phase4_Final_Report",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
